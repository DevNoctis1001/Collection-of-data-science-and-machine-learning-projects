{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Intro_Text_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTguFckTEDWd"
      },
      "source": [
        "# Introduction to Text generation\n",
        "\n",
        "explains how we can split a given corpus of data into features and labels and then train a neural network to predict the next word in a sentence.\n",
        "\n",
        "1. Create a corpus - break the text down to list of sentences.\n",
        "2. Create a word_index(vocabulary) from the text.\n",
        "3. Tokenize the data and create n-gram sequence for each sequence of the corpus.\n",
        "4. Pad those sequences.\n",
        "5. Segregate features from the sequences by reserving the last element of the array as labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##import the required libraries and APIs\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "rQ2CseNtQNuZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFhZpNjHoxSt"
      },
      "source": [
        "## Step 1: Create a corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwT0yxfRgZY_"
      },
      "source": [
        "data = \"October arrived, spreading a damp chill over the grounds and into the castle.\\n Madam Pomfrey, the nurse, was kept busy by a sudden spate of colds among the staff and students.\\n Her Pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. Ginny Weasley, who had been looking pale, was bullied into taking some by Percy.\\n The steam pouring from under her vivid hair gave the impression that her whole head was on fire.\\n Raindrops the size of bullets thundered on the castle windows for days on end; the lake rose, the flower beds turned into muddy streams, and Hagrid's pumpkins swelled to the size of garden sheds.\\n Oliver Wood's enthusiasm for regular training sessions, however, was not dampened, which was why Harry was to be found, late one stormy Saturday afternoon a few days before Halloween, returning to Gryffindor Tower, drenched to the skin and splattered with mud.\"\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##create corpus by lowering the letters and splitting the text by \\n\n",
        "corpus = data.lower().split('\\n')\n",
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd5J7UqHW3qu",
        "outputId": "41b733b8-3b43-4ee5-bffd-cc3fb8335562"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['october arrived, spreading a damp chill over the grounds and into the castle.', ' madam pomfrey, the nurse, was kept busy by a sudden spate of colds among the staff and students.', ' her pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. ginny weasley, who had been looking pale, was bullied into taking some by percy.', ' the steam pouring from under her vivid hair gave the impression that her whole head was on fire.', \" raindrops the size of bullets thundered on the castle windows for days on end; the lake rose, the flower beds turned into muddy streams, and hagrid's pumpkins swelled to the size of garden sheds.\", \" oliver wood's enthusiasm for regular training sessions, however, was not dampened, which was why harry was to be found, late one stormy saturday afternoon a few days before halloween, returning to gryffindor tower, drenched to the skin and splattered with mud.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ce_7Op3eHPS"
      },
      "source": [
        "## Step 2: Train the tokenizer and create word encoding dictionary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "##calculate vocabulary size - +1 for <oov> token\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-6od1FIXHaf",
        "outputId": "0e0b739f-726a-4b3c-d4db-d8cd5c11a5f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'was': 2, 'and': 3, 'to': 4, 'a': 5, 'into': 6, 'of': 7, 'her': 8, 'for': 9, 'on': 10, 'castle': 11, 'by': 12, 'size': 13, 'days': 14, 'october': 15, 'arrived': 16, 'spreading': 17, 'damp': 18, 'chill': 19, 'over': 20, 'grounds': 21, 'madam': 22, 'pomfrey': 23, 'nurse': 24, 'kept': 25, 'busy': 26, 'sudden': 27, 'spate': 28, 'colds': 29, 'among': 30, 'staff': 31, 'students': 32, 'pepperup': 33, 'potion': 34, 'worked': 35, 'instantly': 36, 'though': 37, 'it': 38, 'left': 39, 'drinker': 40, 'smoking': 41, 'at': 42, 'ears': 43, 'several': 44, 'hours': 45, 'afterward': 46, 'ginny': 47, 'weasley': 48, 'who': 49, 'had': 50, 'been': 51, 'looking': 52, 'pale': 53, 'bullied': 54, 'taking': 55, 'some': 56, 'percy': 57, 'steam': 58, 'pouring': 59, 'from': 60, 'under': 61, 'vivid': 62, 'hair': 63, 'gave': 64, 'impression': 65, 'that': 66, 'whole': 67, 'head': 68, 'fire': 69, 'raindrops': 70, 'bullets': 71, 'thundered': 72, 'windows': 73, 'end': 74, 'lake': 75, 'rose': 76, 'flower': 77, 'beds': 78, 'turned': 79, 'muddy': 80, 'streams': 81, \"hagrid's\": 82, 'pumpkins': 83, 'swelled': 84, 'garden': 85, 'sheds': 86, 'oliver': 87, \"wood's\": 88, 'enthusiasm': 89, 'regular': 90, 'training': 91, 'sessions': 92, 'however': 93, 'not': 94, 'dampened': 95, 'which': 96, 'why': 97, 'harry': 98, 'be': 99, 'found': 100, 'late': 101, 'one': 102, 'stormy': 103, 'saturday': 104, 'afternoon': 105, 'few': 106, 'before': 107, 'halloween': 108, 'returning': 109, 'gryffindor': 110, 'tower': 111, 'drenched': 112, 'skin': 113, 'splattered': 114, 'with': 115, 'mud': 116}\n",
            "117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t0633pzeA5y"
      },
      "source": [
        "## Step 3: Create N-gram sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##create n-gram sequences of each text sequence\n",
        "\n",
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "  tokens = tokenizer.texts_to_sequences([line])[0] # get all the tokens of the sequence\n",
        "  \n",
        "  for i in range(1, len(tokens)):\n",
        "    n_gram_sequence = tokens[:i+1] # create n-gram sequences\n",
        "    input_sequences.append(n_gram_sequence)\n",
        "  \n",
        "  print(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJKTe9TeXiw2",
        "outputId": "f9a056e3-3119-4657-c256-42b0ce003017"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15, 16], [15, 16, 17], [15, 16, 17, 5], [15, 16, 17, 5, 18], [15, 16, 17, 5, 18, 19], [15, 16, 17, 5, 18, 19, 20], [15, 16, 17, 5, 18, 19, 20, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1, 11]]\n",
            "[[15, 16], [15, 16, 17], [15, 16, 17, 5], [15, 16, 17, 5, 18], [15, 16, 17, 5, 18, 19], [15, 16, 17, 5, 18, 19, 20], [15, 16, 17, 5, 18, 19, 20, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1, 11], [22, 23], [22, 23, 1], [22, 23, 1, 24], [22, 23, 1, 24, 2], [22, 23, 1, 24, 2, 25], [22, 23, 1, 24, 2, 25, 26], [22, 23, 1, 24, 2, 25, 26, 12], [22, 23, 1, 24, 2, 25, 26, 12, 5], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3, 32]]\n",
            "[[15, 16], [15, 16, 17], [15, 16, 17, 5], [15, 16, 17, 5, 18], [15, 16, 17, 5, 18, 19], [15, 16, 17, 5, 18, 19, 20], [15, 16, 17, 5, 18, 19, 20, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1, 11], [22, 23], [22, 23, 1], [22, 23, 1, 24], [22, 23, 1, 24, 2], [22, 23, 1, 24, 2, 25], [22, 23, 1, 24, 2, 25, 26], [22, 23, 1, 24, 2, 25, 26, 12], [22, 23, 1, 24, 2, 25, 26, 12, 5], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3, 32], [8, 33], [8, 33, 34], [8, 33, 34, 35], [8, 33, 34, 35, 36], [8, 33, 34, 35, 36, 37], [8, 33, 34, 35, 36, 37, 38], [8, 33, 34, 35, 36, 37, 38, 39], [8, 33, 34, 35, 36, 37, 38, 39, 1], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56, 12], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56, 12, 57]]\n",
            "[[15, 16], [15, 16, 17], [15, 16, 17, 5], [15, 16, 17, 5, 18], [15, 16, 17, 5, 18, 19], [15, 16, 17, 5, 18, 19, 20], [15, 16, 17, 5, 18, 19, 20, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1, 11], [22, 23], [22, 23, 1], [22, 23, 1, 24], [22, 23, 1, 24, 2], [22, 23, 1, 24, 2, 25], [22, 23, 1, 24, 2, 25, 26], [22, 23, 1, 24, 2, 25, 26, 12], [22, 23, 1, 24, 2, 25, 26, 12, 5], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3, 32], [8, 33], [8, 33, 34], [8, 33, 34, 35], [8, 33, 34, 35, 36], [8, 33, 34, 35, 36, 37], [8, 33, 34, 35, 36, 37, 38], [8, 33, 34, 35, 36, 37, 38, 39], [8, 33, 34, 35, 36, 37, 38, 39, 1], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56, 12], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56, 12, 57], [1, 58], [1, 58, 59], [1, 58, 59, 60], [1, 58, 59, 60, 61], [1, 58, 59, 60, 61, 8], [1, 58, 59, 60, 61, 8, 62], [1, 58, 59, 60, 61, 8, 62, 63], [1, 58, 59, 60, 61, 8, 62, 63, 64], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2, 10], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2, 10, 69]]\n",
            "[[15, 16], [15, 16, 17], [15, 16, 17, 5], [15, 16, 17, 5, 18], [15, 16, 17, 5, 18, 19], [15, 16, 17, 5, 18, 19, 20], [15, 16, 17, 5, 18, 19, 20, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1, 11], [22, 23], [22, 23, 1], [22, 23, 1, 24], [22, 23, 1, 24, 2], [22, 23, 1, 24, 2, 25], [22, 23, 1, 24, 2, 25, 26], [22, 23, 1, 24, 2, 25, 26, 12], [22, 23, 1, 24, 2, 25, 26, 12, 5], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3, 32], [8, 33], [8, 33, 34], [8, 33, 34, 35], [8, 33, 34, 35, 36], [8, 33, 34, 35, 36, 37], [8, 33, 34, 35, 36, 37, 38], [8, 33, 34, 35, 36, 37, 38, 39], [8, 33, 34, 35, 36, 37, 38, 39, 1], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56, 12], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56, 12, 57], [1, 58], [1, 58, 59], [1, 58, 59, 60], [1, 58, 59, 60, 61], [1, 58, 59, 60, 61, 8], [1, 58, 59, 60, 61, 8, 62], [1, 58, 59, 60, 61, 8, 62, 63], [1, 58, 59, 60, 61, 8, 62, 63, 64], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2, 10], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2, 10, 69], [70, 1], [70, 1, 13], [70, 1, 13, 7], [70, 1, 13, 7, 71], [70, 1, 13, 7, 71, 72], [70, 1, 13, 7, 71, 72, 10], [70, 1, 13, 7, 71, 72, 10, 1], [70, 1, 13, 7, 71, 72, 10, 1, 11], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1, 13], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1, 13, 7], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1, 13, 7, 85], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1, 13, 7, 85, 86]]\n",
            "[[15, 16], [15, 16, 17], [15, 16, 17, 5], [15, 16, 17, 5, 18], [15, 16, 17, 5, 18, 19], [15, 16, 17, 5, 18, 19, 20], [15, 16, 17, 5, 18, 19, 20, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1], [15, 16, 17, 5, 18, 19, 20, 1, 21, 3, 6, 1, 11], [22, 23], [22, 23, 1], [22, 23, 1, 24], [22, 23, 1, 24, 2], [22, 23, 1, 24, 2, 25], [22, 23, 1, 24, 2, 25, 26], [22, 23, 1, 24, 2, 25, 26, 12], [22, 23, 1, 24, 2, 25, 26, 12, 5], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3], [22, 23, 1, 24, 2, 25, 26, 12, 5, 27, 28, 7, 29, 30, 1, 31, 3, 32], [8, 33], [8, 33, 34], [8, 33, 34, 35], [8, 33, 34, 35, 36], [8, 33, 34, 35, 36, 37], [8, 33, 34, 35, 36, 37, 38], [8, 33, 34, 35, 36, 37, 38, 39], [8, 33, 34, 35, 36, 37, 38, 39, 1], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56, 12], [8, 33, 34, 35, 36, 37, 38, 39, 1, 40, 41, 42, 1, 43, 9, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 2, 54, 6, 55, 56, 12, 57], [1, 58], [1, 58, 59], [1, 58, 59, 60], [1, 58, 59, 60, 61], [1, 58, 59, 60, 61, 8], [1, 58, 59, 60, 61, 8, 62], [1, 58, 59, 60, 61, 8, 62, 63], [1, 58, 59, 60, 61, 8, 62, 63, 64], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2, 10], [1, 58, 59, 60, 61, 8, 62, 63, 64, 1, 65, 66, 8, 67, 68, 2, 10, 69], [70, 1], [70, 1, 13], [70, 1, 13, 7], [70, 1, 13, 7, 71], [70, 1, 13, 7, 71, 72], [70, 1, 13, 7, 71, 72, 10], [70, 1, 13, 7, 71, 72, 10, 1], [70, 1, 13, 7, 71, 72, 10, 1, 11], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1, 13], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1, 13, 7], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1, 13, 7, 85], [70, 1, 13, 7, 71, 72, 10, 1, 11, 73, 9, 14, 10, 74, 1, 75, 76, 1, 77, 78, 79, 6, 80, 81, 3, 82, 83, 84, 4, 1, 13, 7, 85, 86], [87, 88], [87, 88, 89], [87, 88, 89, 9], [87, 88, 89, 9, 90], [87, 88, 89, 9, 90, 91], [87, 88, 89, 9, 90, 91, 92], [87, 88, 89, 9, 90, 91, 92, 93], [87, 88, 89, 9, 90, 91, 92, 93, 2], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111, 112], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111, 112, 4], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111, 112, 4, 1], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111, 112, 4, 1, 113], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111, 112, 4, 1, 113, 3], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111, 112, 4, 1, 113, 3, 114], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111, 112, 4, 1, 113, 3, 114, 115], [87, 88, 89, 9, 90, 91, 92, 93, 2, 94, 95, 96, 2, 97, 98, 2, 4, 99, 100, 101, 102, 103, 104, 105, 5, 106, 14, 107, 108, 109, 4, 110, 111, 112, 4, 1, 113, 3, 114, 115, 116]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##pad sequences\n",
        "\n",
        "max_seq_len = max([len(line) for line in input_sequences])\n",
        "\n",
        "input_seq_array = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n",
        "input_seq_array = np.array(input_seq_array)"
      ],
      "metadata": {
        "id": "7V0wCaRPYNJg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJiCqSqYeQDM"
      },
      "source": [
        "## Step 4: Extract features and labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##creating features(X) and label(y)\n",
        "X =  input_seq_array[: , :-1] # every row, unitl the last columns\n",
        "labels = input_seq_array[:, -1] # every row, only the last column\n",
        "\n",
        "##one-hot encode the labels to get y\n",
        "y = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)"
      ],
      "metadata": {
        "id": "xdZHvJyfYnw9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X_GvVM22Wsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3da3eee-4dde-4bb8-c0b4-9145a799245b"
      },
      "source": [
        "sample_word = 'mud'\n",
        "print('sample word: ', sample_word, '\\n')\n",
        "print(tokenizer.word_index[sample_word], '\\n') # example word\n",
        "print(X[0], '\\n')\n",
        "print(y[0], '\\n')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample word:  mud \n",
            "\n",
            "116 \n",
            "\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15] \n",
            "\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFLkSjPoeg-B"
      },
      "source": [
        "## Define the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "\n",
        "embedding_dim = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_seq_len-1)) # we have to minus 1 as the last one will be Label\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dense(vocab_size, activation='softmax')) # as we are predicting words, we have to put vocab_size as each word will be one neuron\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAl9vZJOZjp-",
        "outputId": "7a06d781-96fc-44d4-93bb-cd8244ab36c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 40, 64)            7488      \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               24832     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 117)               7605      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 39,925\n",
            "Trainable params: 39,925\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, epochs=500, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "endF6HylalXQ",
        "outputId": "358e5e75-f969-4cb9-b79e-b8b8fa09f2a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "5/5 [==============================] - 7s 9ms/step - loss: 4.7593 - accuracy: 0.0067\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.7453 - accuracy: 0.0400\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.7316 - accuracy: 0.0933\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.7108 - accuracy: 0.0933\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.6818 - accuracy: 0.0933\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.6348 - accuracy: 0.0933\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.5871 - accuracy: 0.0867\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.5234 - accuracy: 0.0867\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.4890 - accuracy: 0.0867\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.4594 - accuracy: 0.0867\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 4.4185 - accuracy: 0.0867\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 4.3835 - accuracy: 0.0867\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 4.3484 - accuracy: 0.0867\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.3072 - accuracy: 0.0867\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.2704 - accuracy: 0.0867\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.2290 - accuracy: 0.0867\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.1919 - accuracy: 0.1000\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.1485 - accuracy: 0.1000\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.1089 - accuracy: 0.1067\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.0682 - accuracy: 0.1067\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4.0233 - accuracy: 0.1133\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.9829 - accuracy: 0.1133\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.9421 - accuracy: 0.1133\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.8949 - accuracy: 0.1133\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.8538 - accuracy: 0.1200\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.8107 - accuracy: 0.1267\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.7649 - accuracy: 0.1267\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.7294 - accuracy: 0.1267\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.6864 - accuracy: 0.1333\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.6414 - accuracy: 0.1333\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.5984 - accuracy: 0.1467\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.5563 - accuracy: 0.1533\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.5170 - accuracy: 0.1467\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.4858 - accuracy: 0.1533\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.4340 - accuracy: 0.1533\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.4039 - accuracy: 0.1533\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.3657 - accuracy: 0.1600\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.3267 - accuracy: 0.1533\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.2963 - accuracy: 0.1533\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.2601 - accuracy: 0.1600\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 3.2296 - accuracy: 0.1733\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.2077 - accuracy: 0.1800\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.1692 - accuracy: 0.1733\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.1338 - accuracy: 0.1933\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.1070 - accuracy: 0.1800\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.0780 - accuracy: 0.1933\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.0468 - accuracy: 0.1933\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3.0095 - accuracy: 0.2067\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.9897 - accuracy: 0.2067\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.9588 - accuracy: 0.2133\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.9298 - accuracy: 0.2200\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.9128 - accuracy: 0.2067\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.8844 - accuracy: 0.2267\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.8548 - accuracy: 0.2400\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.8295 - accuracy: 0.2333\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.8177 - accuracy: 0.2200\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.8205 - accuracy: 0.2267\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.7792 - accuracy: 0.2267\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.7483 - accuracy: 0.2200\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.7247 - accuracy: 0.2267\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.6918 - accuracy: 0.2400\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.6611 - accuracy: 0.2533\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.6395 - accuracy: 0.2400\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.6179 - accuracy: 0.2533\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.5974 - accuracy: 0.2600\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.5762 - accuracy: 0.2800\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.5493 - accuracy: 0.2800\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.5282 - accuracy: 0.2867\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.5073 - accuracy: 0.3067\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.4892 - accuracy: 0.3133\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.4680 - accuracy: 0.3067\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.4486 - accuracy: 0.2933\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.4325 - accuracy: 0.3333\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.4148 - accuracy: 0.3400\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.3903 - accuracy: 0.3200\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.3732 - accuracy: 0.3267\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.3545 - accuracy: 0.3467\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.3405 - accuracy: 0.3733\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.3311 - accuracy: 0.3467\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.3141 - accuracy: 0.3667\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.2870 - accuracy: 0.3667\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.2733 - accuracy: 0.4000\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.2641 - accuracy: 0.4000\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.2331 - accuracy: 0.3933\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.2194 - accuracy: 0.4133\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.2018 - accuracy: 0.4400\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 2.1886 - accuracy: 0.4333\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.1818 - accuracy: 0.4267\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.1666 - accuracy: 0.4600\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.1482 - accuracy: 0.4667\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.1318 - accuracy: 0.4333\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.1101 - accuracy: 0.4600\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.0957 - accuracy: 0.4667\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.0725 - accuracy: 0.4733\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 2.0603 - accuracy: 0.5267\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.0533 - accuracy: 0.5200\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.0466 - accuracy: 0.5067\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.0225 - accuracy: 0.4867\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 2.0035 - accuracy: 0.5200\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.9897 - accuracy: 0.5467\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.9695 - accuracy: 0.5333\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.9568 - accuracy: 0.5267\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.9413 - accuracy: 0.5533\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.9320 - accuracy: 0.5733\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.9122 - accuracy: 0.5600\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.9136 - accuracy: 0.5733\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.8834 - accuracy: 0.5933\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.8787 - accuracy: 0.5933\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.8548 - accuracy: 0.6200\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.8411 - accuracy: 0.6067\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.8275 - accuracy: 0.6067\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.8147 - accuracy: 0.6400\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.7977 - accuracy: 0.6333\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.7827 - accuracy: 0.6600\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.7681 - accuracy: 0.6600\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.7635 - accuracy: 0.6467\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.7463 - accuracy: 0.6733\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.7393 - accuracy: 0.6467\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.7287 - accuracy: 0.6467\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.7199 - accuracy: 0.6667\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.7043 - accuracy: 0.6533\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.6855 - accuracy: 0.6867\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.6822 - accuracy: 0.7000\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.6652 - accuracy: 0.7067\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.6486 - accuracy: 0.7133\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.6367 - accuracy: 0.7133\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.6235 - accuracy: 0.7067\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.6107 - accuracy: 0.7133\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.6018 - accuracy: 0.7267\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.5872 - accuracy: 0.7133\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.5727 - accuracy: 0.7533\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.5576 - accuracy: 0.7600\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.5557 - accuracy: 0.7667\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.5394 - accuracy: 0.7533\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.5351 - accuracy: 0.7733\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.5340 - accuracy: 0.7600\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.5138 - accuracy: 0.7400\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.4947 - accuracy: 0.7800\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4791 - accuracy: 0.7600\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.4689 - accuracy: 0.7667\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.4521 - accuracy: 0.7867\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.4493 - accuracy: 0.7800\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4508 - accuracy: 0.7800\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.4464 - accuracy: 0.7733\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.4298 - accuracy: 0.7533\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4135 - accuracy: 0.7733\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.4157 - accuracy: 0.7800\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.4029 - accuracy: 0.7933\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.3942 - accuracy: 0.7867\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3776 - accuracy: 0.7667\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.3673 - accuracy: 0.7667\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3550 - accuracy: 0.8067\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3572 - accuracy: 0.8067\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3532 - accuracy: 0.8400\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3362 - accuracy: 0.8267\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3237 - accuracy: 0.8400\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3088 - accuracy: 0.8200\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.3011 - accuracy: 0.8400\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.2949 - accuracy: 0.8467\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.2837 - accuracy: 0.8400\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.2708 - accuracy: 0.8533\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2611 - accuracy: 0.8667\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2530 - accuracy: 0.8733\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2756 - accuracy: 0.8467\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2439 - accuracy: 0.8400\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2430 - accuracy: 0.8333\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2492 - accuracy: 0.8333\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2359 - accuracy: 0.8533\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2321 - accuracy: 0.8467\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.2669 - accuracy: 0.8133\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2782 - accuracy: 0.8200\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2361 - accuracy: 0.8333\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2153 - accuracy: 0.8333\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2119 - accuracy: 0.8133\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2002 - accuracy: 0.8333\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1768 - accuracy: 0.8600\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1644 - accuracy: 0.8600\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1547 - accuracy: 0.8667\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.1469 - accuracy: 0.8667\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1414 - accuracy: 0.8600\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1349 - accuracy: 0.8600\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1658 - accuracy: 0.8600\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2038 - accuracy: 0.8200\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1472 - accuracy: 0.8600\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.1383 - accuracy: 0.8600\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.1404 - accuracy: 0.8600\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1382 - accuracy: 0.8600\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2282 - accuracy: 0.8200\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.2280 - accuracy: 0.8000\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1976 - accuracy: 0.8333\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1852 - accuracy: 0.8533\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.1701 - accuracy: 0.8533\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.1544 - accuracy: 0.8667\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1513 - accuracy: 0.8267\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1354 - accuracy: 0.8933\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1104 - accuracy: 0.8733\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.1156 - accuracy: 0.8667\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 1.1072 - accuracy: 0.8733\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0949 - accuracy: 0.8800\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0755 - accuracy: 0.8867\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0820 - accuracy: 0.8733\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0632 - accuracy: 0.8800\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0775 - accuracy: 0.8933\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0748 - accuracy: 0.8867\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0772 - accuracy: 0.8733\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.0391 - accuracy: 0.9000\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0406 - accuracy: 0.9067\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0647 - accuracy: 0.8800\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0543 - accuracy: 0.8933\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0434 - accuracy: 0.9000\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0207 - accuracy: 0.9133\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1.0016 - accuracy: 0.9267\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.9868 - accuracy: 0.9400\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.9735 - accuracy: 0.9200\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.9653 - accuracy: 0.9200\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.9556 - accuracy: 0.9333\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.9482 - accuracy: 0.9333\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.9410 - accuracy: 0.9267\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9326 - accuracy: 0.9400\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9281 - accuracy: 0.9333\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.9205 - accuracy: 0.9400\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9147 - accuracy: 0.9400\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9082 - accuracy: 0.9400\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9015 - accuracy: 0.9533\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8938 - accuracy: 0.9400\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8865 - accuracy: 0.9467\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8806 - accuracy: 0.9533\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.8761 - accuracy: 0.9467\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8732 - accuracy: 0.9600\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8651 - accuracy: 0.9400\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8594 - accuracy: 0.9400\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8523 - accuracy: 0.9600\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8482 - accuracy: 0.9600\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8444 - accuracy: 0.9600\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8375 - accuracy: 0.9600\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8353 - accuracy: 0.9600\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8255 - accuracy: 0.9667\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.8217 - accuracy: 0.9600\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8176 - accuracy: 0.9667\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8098 - accuracy: 0.9667\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8059 - accuracy: 0.9667\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.8009 - accuracy: 0.9667\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7938 - accuracy: 0.9667\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.7906 - accuracy: 0.9600\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7848 - accuracy: 0.9867\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7848 - accuracy: 0.9733\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7750 - accuracy: 0.9867\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7709 - accuracy: 0.9800\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7639 - accuracy: 0.9733\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7613 - accuracy: 0.9733\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7568 - accuracy: 0.9733\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7505 - accuracy: 0.9867\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7493 - accuracy: 0.9667\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7463 - accuracy: 0.9800\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7395 - accuracy: 0.9800\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7367 - accuracy: 0.9733\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.7486 - accuracy: 0.9533\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.7424 - accuracy: 0.9600\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.7366 - accuracy: 0.9600\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7286 - accuracy: 0.9733\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7202 - accuracy: 0.9733\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7148 - accuracy: 0.9800\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7040 - accuracy: 0.9800\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7057 - accuracy: 0.9733\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6961 - accuracy: 0.9800\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6912 - accuracy: 0.9867\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6850 - accuracy: 0.9933\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6778 - accuracy: 0.9933\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6724 - accuracy: 0.9867\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6677 - accuracy: 0.9867\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6662 - accuracy: 0.9867\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6569 - accuracy: 0.9867\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6540 - accuracy: 0.9867\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6533 - accuracy: 0.9867\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6543 - accuracy: 0.9800\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6506 - accuracy: 0.9800\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6423 - accuracy: 0.9867\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6350 - accuracy: 0.9867\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6329 - accuracy: 0.9800\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6261 - accuracy: 0.9867\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6256 - accuracy: 0.9867\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6196 - accuracy: 0.9867\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6172 - accuracy: 0.9867\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6096 - accuracy: 0.9867\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6064 - accuracy: 0.9933\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6023 - accuracy: 0.9867\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5981 - accuracy: 0.9867\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5948 - accuracy: 0.9867\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5893 - accuracy: 0.9867\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5865 - accuracy: 0.9867\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5818 - accuracy: 0.9867\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5786 - accuracy: 0.9867\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5736 - accuracy: 0.9933\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5702 - accuracy: 0.9933\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5667 - accuracy: 0.9933\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5635 - accuracy: 0.9933\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.9933\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.9933\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5538 - accuracy: 0.9933\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.9933\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5472 - accuracy: 0.9933\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5444 - accuracy: 0.9933\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5429 - accuracy: 0.9933\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5375 - accuracy: 0.9933\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5344 - accuracy: 0.9933\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5290 - accuracy: 0.9933\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.9933\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5220 - accuracy: 0.9933\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5190 - accuracy: 0.9933\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5163 - accuracy: 0.9933\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.9933\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5091 - accuracy: 0.9933\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5041 - accuracy: 0.9933\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5025 - accuracy: 0.9933\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4990 - accuracy: 0.9933\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5011 - accuracy: 0.9933\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4968 - accuracy: 0.9933\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4922 - accuracy: 0.9933\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4873 - accuracy: 0.9933\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.9933\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4803 - accuracy: 0.9933\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4777 - accuracy: 0.9933\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4734 - accuracy: 0.9933\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4741 - accuracy: 0.9933\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4755 - accuracy: 0.9933\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4692 - accuracy: 0.9933\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4644 - accuracy: 0.9933\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4794 - accuracy: 0.9867\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5019 - accuracy: 0.9800\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5491 - accuracy: 0.9600\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7765 - accuracy: 0.8800\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7877 - accuracy: 0.8667\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.7341 - accuracy: 0.8933\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6440 - accuracy: 0.9267\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.6273 - accuracy: 0.9200\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6099 - accuracy: 0.9467\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.5880 - accuracy: 0.9467\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5769 - accuracy: 0.9533\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5538 - accuracy: 0.9667\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5510 - accuracy: 0.9600\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5464 - accuracy: 0.9733\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5430 - accuracy: 0.9733\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.5450 - accuracy: 0.9667\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5457 - accuracy: 0.9800\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5261 - accuracy: 0.9667\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5199 - accuracy: 0.9733\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5107 - accuracy: 0.9733\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4979 - accuracy: 0.9800\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4929 - accuracy: 0.9800\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4855 - accuracy: 0.9733\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4766 - accuracy: 0.9733\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4712 - accuracy: 0.9733\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4649 - accuracy: 0.9800\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4594 - accuracy: 0.9800\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4558 - accuracy: 0.9800\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4500 - accuracy: 0.9867\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4457 - accuracy: 0.9867\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4397 - accuracy: 0.9867\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4357 - accuracy: 0.9867\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4314 - accuracy: 0.9867\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4271 - accuracy: 0.9867\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4230 - accuracy: 0.9933\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4198 - accuracy: 0.9867\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4165 - accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4130 - accuracy: 0.9933\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4097 - accuracy: 0.9933\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4062 - accuracy: 0.9933\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4027 - accuracy: 0.9933\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3992 - accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3974 - accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3946 - accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3909 - accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3877 - accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3846 - accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3824 - accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3788 - accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3777 - accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3745 - accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3725 - accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3722 - accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3665 - accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3634 - accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3605 - accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3584 - accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3560 - accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3529 - accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3479 - accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3449 - accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3422 - accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3400 - accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3381 - accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3347 - accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3332 - accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3312 - accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3266 - accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3233 - accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3206 - accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3202 - accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3167 - accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3183 - accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3137 - accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3117 - accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3098 - accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.3073 - accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3041 - accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3024 - accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3015 - accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3018 - accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2977 - accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3058 - accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3275 - accuracy: 0.9933\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3675 - accuracy: 0.9667\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3178 - accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.3044 - accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3213 - accuracy: 0.9867\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3087 - accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2996 - accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3052 - accuracy: 0.9933\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2934 - accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.2882 - accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2798 - accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2741 - accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2691 - accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2689 - accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2677 - accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2632 - accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.2609 - accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2591 - accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2566 - accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2546 - accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2521 - accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2504 - accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2488 - accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2476 - accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2467 - accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2437 - accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2439 - accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2421 - accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.2406 - accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2385 - accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2361 - accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2344 - accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2326 - accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2309 - accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2294 - accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2280 - accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2261 - accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2253 - accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2236 - accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2218 - accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2208 - accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2195 - accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2184 - accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2169 - accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2159 - accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2145 - accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2121 - accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2108 - accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2091 - accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2084 - accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2060 - accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2052 - accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2037 - accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2020 - accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2009 - accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1997 - accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1986 - accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1973 - accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1957 - accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1946 - accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1935 - accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1919 - accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1904 - accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1896 - accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1882 - accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1870 - accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1855 - accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1845 - accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1830 - accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1820 - accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1809 - accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1799 - accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1789 - accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.1780 - accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1760 - accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1755 - accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1741 - accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1731 - accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1721 - accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1708 - accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1700 - accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1686 - accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1677 - accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1666 - accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1653 - accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1643 - accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1632 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDpFBjlzm1Up"
      },
      "source": [
        "## Visualize metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc7nqPbg5tBy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_metric(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.show()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHHODnWIrobv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "2966c340-1cb2-4b03-a6d9-3903bf56cca4"
      },
      "source": [
        "plot_metric(history, 'accuracy')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GLsNdvSm3uv"
      },
      "source": [
        "## Generate new text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"It was a cold night.\"\n",
        "\n",
        "# add number of words that we want to predict\n",
        "num_next_words = 100\n",
        "\n",
        "# run and loop to predict, and concatenate the words\n",
        "for _ in range(num_next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
        "\n",
        "  ##predict the class using the trained model\n",
        "  probabilities = model.predict(token_list)\n",
        "  predicted = np.argmax(probabilities, axis=-1)[0]\n",
        "\n",
        "  if predicted !=0:\n",
        "    #reference the predicted class with the vocabulary\n",
        "    output_word = tokenizer.index_word[predicted]\n",
        "    seed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zb1tamOaskd",
        "outputId": "93cba88a-da8d-46af-b0ef-0bc2241e1b60"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a cold night. the steam pouring from under her vivid hair impression that her whole head was on fire fire fire was bullied into taking some by percy percy percy percy a days drenched drenched to drenched splattered with mud with mud splattered with mud mud splattered with mud mud the splattered with mud mud mud mud splattered with mud the mud mud mud mud and size of splattered with mud mud mud mud splattered with and and garden students a returning to splattered with mud splattered with mud splattered with mud with mud the splattered with mud mud skin and mud mud\n"
          ]
        }
      ]
    }
  ]
}