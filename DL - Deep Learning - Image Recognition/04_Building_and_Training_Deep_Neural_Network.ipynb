{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Building_and_Training_Deep_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxGT_8u-jq4y"
      },
      "source": [
        "# 1) Setting up Neural Network for Training\r\n",
        "### batch_size\r\n",
        "- `batch_size`:  how many images that we want to feed into the network at once during training.\r\n",
        "- **Typical batch_size is between 32 and 128 images**, but can expirement freely.\r\n",
        "\r\n",
        "If we set the number too low, training will take a long time and might not finish.  If we set the number too high, we'll run out of memory on our computer.\r\n",
        "\r\n",
        "### epoch\r\n",
        "- we need to decide how many times we want to go through our training data set during the process.  One full pass through the entire training dataset is called an `epoch`.  \r\n",
        "- The more epoches we set, the more chance the neural network has to learn; but the longer training process will take. eventually you will hit the point where doing additional training doesn't help anymore. so finding the right number take expirmentation.\r\n",
        "- The larger the data set, the less training passes you'll do on it. For extremelly large dataset with millions of images you might only do five passes, etc.\r\n",
        "\r\n",
        "### shuffle\r\n",
        "- we need to make sure Keras randomizes the order of training data. It's very important that neural network sees the training data baches in random order, so that the order of training data doesn't influcence the training. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWsi0yUrYwyT"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.datasets import cifar10\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "# load data\r\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
        "\r\n",
        "# Normalize data\r\n",
        "x_train = x_train.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "x_train = x_train / 255\r\n",
        "x_test = x_test / 255\r\n",
        "\r\n",
        "# Categorical encoding for labels\r\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\r\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnrcRTDIY4Xn",
        "outputId": "e2208558-90a9-4b66-dda1-181d33e056d1"
      },
      "source": [
        "# Create model and Add layers\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(32, 32, 3))) # we want to put some padding\r\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\r\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\r\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\r\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "\r\n",
        "model.add(Dense(512, activation='relu', input_shape=(32, 32, 3)))\r\n",
        "model.add(Dropout(0.50))\r\n",
        "\r\n",
        "model.add(Dense(10, activation='softmax')) # multiclass classification\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(\r\n",
        "    loss='categorical_crossentropy',\r\n",
        "    optimizer='adam',\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "\r\n",
        "# Summary of model\r\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-JJAcjRY8i7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba7cf37-1dfd-44cd-f492-f57aa9e007ba"
      },
      "source": [
        "# Training the model\r\n",
        "model.fit(\r\n",
        "    x_train,\r\n",
        "    y_train,\r\n",
        "    batch_size=64,\r\n",
        "    epochs=30,\r\n",
        "    validation_data=(x_test, y_test),\r\n",
        "    shuffle=True\r\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4050 - accuracy: 0.8572 - val_loss: 0.6606 - val_accuracy: 0.7920\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3909 - accuracy: 0.8622 - val_loss: 0.6531 - val_accuracy: 0.7953\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3866 - accuracy: 0.8605 - val_loss: 0.6591 - val_accuracy: 0.7929\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3848 - accuracy: 0.8622 - val_loss: 0.6652 - val_accuracy: 0.7904\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3829 - accuracy: 0.8655 - val_loss: 0.6706 - val_accuracy: 0.7888\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3748 - accuracy: 0.8674 - val_loss: 0.6781 - val_accuracy: 0.7901\n",
            "Epoch 7/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3693 - accuracy: 0.8697 - val_loss: 0.6619 - val_accuracy: 0.7935\n",
            "Epoch 8/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3685 - accuracy: 0.8698 - val_loss: 0.6524 - val_accuracy: 0.7911\n",
            "Epoch 9/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3654 - accuracy: 0.8699 - val_loss: 0.6713 - val_accuracy: 0.7902\n",
            "Epoch 10/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3688 - accuracy: 0.8691 - val_loss: 0.6682 - val_accuracy: 0.7907\n",
            "Epoch 11/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3559 - accuracy: 0.8742 - val_loss: 0.6792 - val_accuracy: 0.7974\n",
            "Epoch 12/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3497 - accuracy: 0.8768 - val_loss: 0.6737 - val_accuracy: 0.7966\n",
            "Epoch 13/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3451 - accuracy: 0.8762 - val_loss: 0.6907 - val_accuracy: 0.7926\n",
            "Epoch 14/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3483 - accuracy: 0.8764 - val_loss: 0.6928 - val_accuracy: 0.7932\n",
            "Epoch 15/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3438 - accuracy: 0.8784 - val_loss: 0.6981 - val_accuracy: 0.7896\n",
            "Epoch 16/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3378 - accuracy: 0.8809 - val_loss: 0.6890 - val_accuracy: 0.7924\n",
            "Epoch 17/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3271 - accuracy: 0.8846 - val_loss: 0.6644 - val_accuracy: 0.7979\n",
            "Epoch 18/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3307 - accuracy: 0.8822 - val_loss: 0.6739 - val_accuracy: 0.7977\n",
            "Epoch 19/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3260 - accuracy: 0.8855 - val_loss: 0.6575 - val_accuracy: 0.8000\n",
            "Epoch 20/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3339 - accuracy: 0.8836 - val_loss: 0.7245 - val_accuracy: 0.7993\n",
            "Epoch 21/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3225 - accuracy: 0.8861 - val_loss: 0.6889 - val_accuracy: 0.7946\n",
            "Epoch 22/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3224 - accuracy: 0.8854 - val_loss: 0.6757 - val_accuracy: 0.8019\n",
            "Epoch 23/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3198 - accuracy: 0.8861 - val_loss: 0.6959 - val_accuracy: 0.7975\n",
            "Epoch 24/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3180 - accuracy: 0.8880 - val_loss: 0.6837 - val_accuracy: 0.7944\n",
            "Epoch 25/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3179 - accuracy: 0.8884 - val_loss: 0.7068 - val_accuracy: 0.7949\n",
            "Epoch 26/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3106 - accuracy: 0.8895 - val_loss: 0.6833 - val_accuracy: 0.8005\n",
            "Epoch 27/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3058 - accuracy: 0.8929 - val_loss: 0.6922 - val_accuracy: 0.7971\n",
            "Epoch 28/30\n",
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3152 - accuracy: 0.8894 - val_loss: 0.7065 - val_accuracy: 0.7946\n",
            "Epoch 29/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.3015 - accuracy: 0.8935 - val_loss: 0.7007 - val_accuracy: 0.7950\n",
            "Epoch 30/30\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2989 - accuracy: 0.8954 - val_loss: 0.6796 - val_accuracy: 0.8001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7e0bf57c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6SJgOluolxc"
      },
      "source": [
        "--------\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOmCejyNnipf"
      },
      "source": [
        "# 2) Training Neural Network and Saving weights\r\n",
        "\r\n",
        "After training completes, we want to save the trained neural network to a file. so we can use it to recognize objects and images in other programs.\r\n",
        "\r\n",
        "## 2.1) Saving the neural network\r\n",
        "- First we want to save the structure of the neural network itself. That includes which layers get created and the order they are hooked together.\r\n",
        "\r\n",
        "## 2.2) Saving the neural network's trained weights\r\n",
        "- Second we want to save weights of trained neural network. As neural network is trained, the weights of each nodes are adjusted to control how much the signals flow through the network. So by saving the weights, we are acutally saving how neural network actually works.\r\n",
        "- HDF5 format is designed for saving and loading large binary files efficiently. by convention, we use extension `.h5` to indicate the format of the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQW0Q__-nhHy"
      },
      "source": [
        "# Save neural  network structure\r\n",
        "model_structure = model.to_json()\r\n",
        "f = Path('model_structure.json')\r\n",
        "f.write_text(model_structure)\r\n",
        "\r\n",
        "# Save neural network's trained weights\r\n",
        "model.save_weights(\"model_weights.h5\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjv56oatm8Cp"
      },
      "source": [
        "--------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOzqdr4XsFQ_"
      },
      "source": [
        "# 3) Making Predictions with trained neural network\r\n",
        "- Keras expects images to be provided in batches (even if we want to predict one image)\r\n",
        "- there is one trick we can use if we want to predict only one image `numpy.expand_dims()`. We need to provide `axis=0` stating that new axis will be first dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_93YP6yQzHK",
        "outputId": "4de69dda-f7c2-4ae1-e460-5bb15f95e4c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo3vP0rNsJUl"
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQqfQDDks4t_"
      },
      "source": [
        "# These are the CIFAR10 class labels from the training data (in order from 0 to 9)\r\n",
        "class_labels = [\r\n",
        "    \"Plane\",\r\n",
        "    \"Car\",\r\n",
        "    \"Bird\",\r\n",
        "    \"Cat\",\r\n",
        "    \"Deer\",\r\n",
        "    \"Dog\",\r\n",
        "    \"Frog\",\r\n",
        "    \"Horse\",\r\n",
        "    \"Boat\",\r\n",
        "    \"Truck\"\r\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CdwqJjYtCbQ",
        "outputId": "820bc20a-f7c6-4492-c030-1a53c8427d26"
      },
      "source": [
        "# Load the json file that contains the model's structure\r\n",
        "file_path = '/content/drive/MyDrive/Deeplearning_image_recognition/'\r\n",
        "f = Path(file_path + 'model_structure.json')\r\n",
        "model_structure = f.read_text()\r\n",
        "\r\n",
        "# Recreate the Keras model object from the json data\r\n",
        "model = model_from_json(model_structure)\r\n",
        "\r\n",
        "# Re-load the model's trained weights\r\n",
        "model.load_weights(file_path + 'model_weights.h5')\r\n",
        "\r\n",
        "#--------- Testing Image ------------- #\r\n",
        "# Load an image file to test, resizing it to 32x32 pixels (as required by this model)\r\n",
        "img = image.load_img(file_path + 'frog.png', target_size=(32, 32))\r\n",
        "\r\n",
        "# Convert the image to a 3D numpy array, with normalized data\r\n",
        "image_to_test = image.img_to_array(img) / 255\r\n",
        "\r\n",
        "# Add a fourth dimension to the image (since Keras expects a list of images, not a single image)\r\n",
        "list_of_images = np.expand_dims(image_to_test, axis=0)\r\n",
        "\r\n",
        "# Make a prediction using the model\r\n",
        "results = model.predict(list_of_images)\r\n",
        "\r\n",
        "# Since we are only testing one image, we only need to check the first result\r\n",
        "single_result = results[0]\r\n",
        "\r\n",
        "# We will get a likelihood score for all 10 possible classes. Find out which class had the highest score.\r\n",
        "most_likely_class_index = int(np.argmax(single_result))\r\n",
        "class_likelihood = single_result[most_likely_class_index]\r\n",
        "\r\n",
        "# Get the name of the most likely class\r\n",
        "class_label = class_labels[most_likely_class_index]\r\n",
        "\r\n",
        "# Print the result\r\n",
        "print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likelihood))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is image is a Frog - Likelihood: 0.978655\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}