{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_Using_Image_Recognition_API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5zFsuVy6ZQZ"
      },
      "source": [
        "# Using Image Recognition API\n",
        "\n",
        "- [Google Cloud Vision](https://cloud.google.com/vision)\n",
        "- Amazon Rekognition\n",
        "- Microsoft Azure Computer Vision\n",
        "- Many smaller competitors with unique features\n",
        "\n",
        "### When to Use an Off-the-Shelf API\n",
        "- Don't have any training data\n",
        "- Detecting many different kinds of object\n",
        "- Detecting common objects\n",
        "- Low budget (money or time)\n",
        "\n",
        "### When to Build Your Own Model\n",
        "- Have access to specialized training data\n",
        "- Detecting uncommon object\n",
        "- Training data is very sensitive or proprietary\n",
        "\n",
        "### When to Use a Hybrid Solution\n",
        "- Need other features like logo detection and landmark detection\n",
        "- Need OCR (optical character recognition) which is difficult to build.\n",
        "\n",
        "-------\n",
        "\n",
        "# 1) Google Cloud Vision API Key Creation\n",
        "\n",
        "- https://console.cloud.google.com/\n",
        "- enable Cloud Vision API ( menu bar => API and Servies > API Library)\n",
        "- type `Cloud Vision` and enable it.\n",
        "- Create Credentials => Sevice Account Key\n",
        "  - Role: Actions Viewers\n",
        "  - Then create New Key => JSON => key will be downloaded.\n",
        "\n",
        "  ------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12V3ER4I9HDk"
      },
      "source": [
        "# 2) Recognizing objects in photographs with Google Cloud Vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs42S9jEKZMI"
      },
      "source": [
        "file_path = '/content/drive/MyDrive/Deeplearning_image_recognition/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL0CUlzrLZL-"
      },
      "source": [
        "from base64 import b64encode\n",
        "\n",
        "import googleapiclient.discovery\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Settings\n",
        "IMAGE_FILE = file_path + \"road_sign.jpg\"\n",
        "CREDENTIALS_FILE = file_path + \"credentials.json\"\n",
        "\n",
        "print(CREDENTIALS_FILE)\n",
        "\n",
        "# Connect to the Google Cloud-ML Service\n",
        "credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
        "service = googleapiclient.discovery.build('vision', 'v1', credentials=credentials)\n",
        "\n",
        "# Read file and convert it to a base64 encoding\n",
        "with open(IMAGE_FILE, \"rb\") as f:\n",
        "    image_data = f.read()\n",
        "    encoded_image_data = b64encode(image_data).decode('UTF-8')\n",
        "\n",
        "# Create the request object for the Google Vision API\n",
        "batch_request = [{\n",
        "    'image': {\n",
        "        'content': encoded_image_data\n",
        "    },\n",
        "    'features': [\n",
        "        {\n",
        "            'type': 'LABEL_DETECTION'\n",
        "        }\n",
        "    ]\n",
        "}]\n",
        "request = service.images().annotate(body={'requests': batch_request})\n",
        "\n",
        "# Send the request to Google\n",
        "response = request.execute()\n",
        "\n",
        "# Check for errors\n",
        "if 'error' in response:\n",
        "    raise RuntimeError(response['error'])\n",
        "\n",
        "# Print the results\n",
        "labels = response['responses'][0]['labelAnnotations']\n",
        "\n",
        "for label in labels:\n",
        "    print(label['description'], label['score'])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_SQezVHM7zk"
      },
      "source": [
        "------\n",
        "\n",
        "# 3) Extracting text from images with Google Cloud Vision\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVawIT-sNKQy"
      },
      "source": [
        "from base64 import b64encode\n",
        "\n",
        "import googleapiclient.discovery\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Change this values to match your project\n",
        "IMAGE_FILE = file_path + \"text.png\"\n",
        "CREDENTIALS_FILE = file_path + \"credentials.json\"\n",
        "\n",
        "# Connect to the Google Cloud-ML Service\n",
        "credentials = GoogleCredentials.from_stream(CREDENTIALS_FILE)\n",
        "service = googleapiclient.discovery.build('vision', 'v1', credentials=credentials)\n",
        "\n",
        "# Read file and convert it to a base64 encoding\n",
        "with open(IMAGE_FILE, \"rb\") as f:\n",
        "    image_data = f.read()\n",
        "    encoded_image_data = b64encode(image_data).decode('UTF-8')\n",
        "\n",
        "# Create the request object for the Google Vision API\n",
        "batch_request = [{\n",
        "    'image': {\n",
        "        'content': encoded_image_data\n",
        "    },\n",
        "    'features': [\n",
        "        {\n",
        "            'type': 'TEXT_DETECTION'\n",
        "        }\n",
        "    ]\n",
        "}]\n",
        "request = service.images().annotate(body={'requests': batch_request})\n",
        "\n",
        "# Send the request to Google\n",
        "response = request.execute()\n",
        "\n",
        "# Check for errors\n",
        "if 'error' in response:\n",
        "    raise RuntimeError(response['error'])\n",
        "\n",
        "# Print the results\n",
        "extracted_texts = response['responses'][0]['textAnnotations']\n",
        "\n",
        "# Print the first piece of text found in the image\n",
        "extracted_text = extracted_texts[0]\n",
        "print(extracted_text['description'])\n",
        "\n",
        "# Print the location where the text was detected\n",
        "print(extracted_text['boundingPoly'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}