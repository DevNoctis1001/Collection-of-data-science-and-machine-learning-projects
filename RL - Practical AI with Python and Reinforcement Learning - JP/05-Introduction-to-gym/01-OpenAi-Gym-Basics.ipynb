{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "filled-workstation",
   "metadata": {},
   "source": [
    "<center><em>Copyright by Pierian Data Inc.</em></center>\n",
    "<center><em>For more information, visit us at <a href='http://www.pieriandata.com'>www.pieriandata.com</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-montana",
   "metadata": {},
   "source": [
    "# Open AI Gym Basics\n",
    "\n",
    "Let's explore the basics of a **gym** environment, later on we wil interact with it and create agents to learn from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-insurance",
   "metadata": {},
   "source": [
    "In this notebook we will get to know the open ai gym library and its environments:\n",
    "\n",
    "https://gym.openai.com/\n",
    "\n",
    "It contains various implementations of tasks on which you can try Reinforcement Learning agents. \n",
    "\n",
    "At first we will import the necessary environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64743024",
   "metadata": {},
   "source": [
    "### Installation NOTE:\n",
    "https://stackoverflow.com/questions/69442971/error-in-importing-environment-openai-gym\n",
    "\n",
    "`pip install gym[atari,accept-rom-license]==0.21.0`\n",
    "\n",
    "`pip install pygame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30fff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ale_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b782544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym: 0.21.0\n",
      "ale_py: 0.7.5\n"
     ]
    }
   ],
   "source": [
    "print('gym:', gym.__version__)\n",
    "print('ale_py:', ale_py.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c625566",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da14f7",
   "metadata": {},
   "source": [
    "### Import stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ada6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import ale_py\n",
    "\n",
    "import time # to slow done the game rendering to human speed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-surname",
   "metadata": {},
   "source": [
    "Now we can go and chose an environment we want to try and where we want to train an agent on from here:<br />\n",
    "https://gym.openai.com/envs/\n",
    "\n",
    "Let's say we want to play the **breakout game** https://gym.openai.com/envs/Breakout-v0/, then we need to perform the following two steps:\n",
    "\n",
    "1. Define the name of the environment\n",
    "2. Create the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafb519",
   "metadata": {},
   "source": [
    "### Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50805b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'ALE/Breakout-v5' # Use the exact same name as stated on gym.openai\n",
    "env = gym.make(env_name) # use gym.make to create your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-pitch",
   "metadata": {},
   "source": [
    "Thats all! You successfully created the environment!<br />\n",
    "Those steps are identical for all environments.\n",
    "\n",
    "If you want to take a look at your game, gym comes with a handy utils function called **play** for Atari games.<br />\n",
    "Note that you start the game with *space* and move with *a* and *d*\n",
    "\n",
    "How many points can you score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33147d05",
   "metadata": {},
   "source": [
    "### Interacting with Game Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "855ece63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.7.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from gym.utils import play    # import the play module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82a6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "play.play(env, zoom=2)     # call the play function\n",
    "\n",
    "# now the game will launch\n",
    "# controls : AWSE , space => start the ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-jackson",
   "metadata": {},
   "source": [
    "Now after getting to know how we can select an environment and interact with it, it is time to dive deeper into the world of gym.\n",
    "\n",
    "Gym offers us many functions to interact with the created environment. The most important are:\n",
    "\n",
    "* reset() - which resets the state of the environment to the initial state. I.e it restarts the game \n",
    "* step(action) - performs an action on your environment. In our case it either starts the game or moves to the left, right, or just remains at the current position. It returns the current state of the environment, the reward, if the game is done and some debugging information\n",
    "* render(mode) - Renders your environment and displays it on your monitor\n",
    "\n",
    "We will get to know those functions in the next few cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-corps",
   "metadata": {},
   "source": [
    "First we will take a look at the **render** function:<br />\n",
    "render(mode) takes one argument, namely the render *mode*. *mode* can take two possible values:\n",
    "* \"human\"\n",
    "* \"rgb_array\"\n",
    "\n",
    "\"human\" directly displays the game on your screen, while \"rgb_array\" returns the array containing the state of the current environment aka the image render shows us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac8a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step in range(100):\n",
    "#     env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba535e8",
   "metadata": {},
   "source": [
    "### Render in RGB mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df22f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = env.render(mode='rgb_array') # returns the image as a 2d numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98df1456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "609c9da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4ab72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200  72  72]\n"
     ]
    }
   ],
   "source": [
    "print(array[60][50])  # display the colour of some pixel (row 60 and column 50 - so the red blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91640e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(array); # you can use matplotlib to take a look at your environment - it is the same image as above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-circular",
   "metadata": {},
   "source": [
    "Note that even we ran 1000 steps over the environment, nothing happened! <br />\n",
    "This is because no action was taken on this environment.\n",
    "\n",
    "This is the point where the **step** function joins our game. It performs a selected action on our environment, e.g moving to the left.\n",
    "\n",
    "You can take a look at the possible actions via the **action_space.n** property.\n",
    "It returns 4 for our game which is in line with our above findings that we can either start the game, move left or right, or stand still."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3e16bf",
   "metadata": {},
   "source": [
    "### Action Space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alternate-wonder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gym.wrappers.time_limit.TimeLimit"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015cbd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ed93f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd2d7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 possible actions\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {env.action_space.n} possible actions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-mobile",
   "metadata": {},
   "source": [
    "Now it is time to watch some action happening. For this we can select a random possible action.\n",
    "We could do this by using **numpy.random.randint(0, 4)** or by using the provided sample function **env.action_space.sample()** which directly returns you a possible action.\n",
    "\n",
    "Note how the \"ale.lives\" info reduces for each live you lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbfd3321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d107d40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 4, 'frame_number': 505}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 8, 'frame_number': 509}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 12, 'frame_number': 513}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 16, 'frame_number': 517}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 20, 'frame_number': 521}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 24, 'frame_number': 525}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 28, 'frame_number': 529}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 32, 'frame_number': 533}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 36, 'frame_number': 537}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 40, 'frame_number': 541}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 44, 'frame_number': 545}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 48, 'frame_number': 549}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 52, 'frame_number': 553}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 56, 'frame_number': 557}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 60, 'frame_number': 561}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 64, 'frame_number': 565}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 68, 'frame_number': 569}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 72, 'frame_number': 573}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 76, 'frame_number': 577}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 80, 'frame_number': 581}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 84, 'frame_number': 585}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 88, 'frame_number': 589}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 92, 'frame_number': 593}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 96, 'frame_number': 597}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 100, 'frame_number': 601}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 104, 'frame_number': 605}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 108, 'frame_number': 609}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 5, 'episode_frame_number': 112, 'frame_number': 613}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 116, 'frame_number': 617}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 120, 'frame_number': 621}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 124, 'frame_number': 625}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 128, 'frame_number': 629}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 132, 'frame_number': 633}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 136, 'frame_number': 637}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 140, 'frame_number': 641}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 144, 'frame_number': 645}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 148, 'frame_number': 649}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 152, 'frame_number': 653}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 156, 'frame_number': 657}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 160, 'frame_number': 661}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 164, 'frame_number': 665}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 168, 'frame_number': 669}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 172, 'frame_number': 673}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 176, 'frame_number': 677}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 180, 'frame_number': 681}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 184, 'frame_number': 685}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 188, 'frame_number': 689}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 192, 'frame_number': 693}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 196, 'frame_number': 697}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 200, 'frame_number': 701}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 204, 'frame_number': 705}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 208, 'frame_number': 709}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 212, 'frame_number': 713}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 216, 'frame_number': 717}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 220, 'frame_number': 721}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 224, 'frame_number': 725}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 228, 'frame_number': 729}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 232, 'frame_number': 733}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 236, 'frame_number': 737}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 240, 'frame_number': 741}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 244, 'frame_number': 745}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 248, 'frame_number': 749}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 252, 'frame_number': 753}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 256, 'frame_number': 757}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 260, 'frame_number': 761}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 264, 'frame_number': 765}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 268, 'frame_number': 769}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 272, 'frame_number': 773}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 276, 'frame_number': 777}\n",
      "Reward: 1.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 280, 'frame_number': 781}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 284, 'frame_number': 785}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 288, 'frame_number': 789}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 292, 'frame_number': 793}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 296, 'frame_number': 797}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 300, 'frame_number': 801}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 304, 'frame_number': 805}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 308, 'frame_number': 809}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 312, 'frame_number': 813}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 316, 'frame_number': 817}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 320, 'frame_number': 821}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 324, 'frame_number': 825}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 328, 'frame_number': 829}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 332, 'frame_number': 833}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 336, 'frame_number': 837}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 340, 'frame_number': 841}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 344, 'frame_number': 845}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 348, 'frame_number': 849}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 352, 'frame_number': 853}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 356, 'frame_number': 857}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 360, 'frame_number': 861}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 364, 'frame_number': 865}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 368, 'frame_number': 869}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 372, 'frame_number': 873}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 376, 'frame_number': 877}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 380, 'frame_number': 881}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 384, 'frame_number': 885}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 388, 'frame_number': 889}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 392, 'frame_number': 893}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 396, 'frame_number': 897}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 4, 'episode_frame_number': 400, 'frame_number': 901}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 404, 'frame_number': 905}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 408, 'frame_number': 909}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 412, 'frame_number': 913}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 416, 'frame_number': 917}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 420, 'frame_number': 921}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 424, 'frame_number': 925}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 428, 'frame_number': 929}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 432, 'frame_number': 933}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 436, 'frame_number': 937}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 440, 'frame_number': 941}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 444, 'frame_number': 945}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 448, 'frame_number': 949}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 452, 'frame_number': 953}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 456, 'frame_number': 957}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 460, 'frame_number': 961}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 464, 'frame_number': 965}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 468, 'frame_number': 969}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 472, 'frame_number': 973}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 476, 'frame_number': 977}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 480, 'frame_number': 981}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 484, 'frame_number': 985}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 488, 'frame_number': 989}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 492, 'frame_number': 993}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 496, 'frame_number': 997}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 500, 'frame_number': 1001}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 3, 'episode_frame_number': 504, 'frame_number': 1005}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 508, 'frame_number': 1009}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 512, 'frame_number': 1013}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 516, 'frame_number': 1017}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 520, 'frame_number': 1021}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 524, 'frame_number': 1025}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 528, 'frame_number': 1029}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 532, 'frame_number': 1033}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 536, 'frame_number': 1037}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 540, 'frame_number': 1041}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 544, 'frame_number': 1045}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 548, 'frame_number': 1049}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 552, 'frame_number': 1053}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 556, 'frame_number': 1057}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 560, 'frame_number': 1061}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 564, 'frame_number': 1065}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 568, 'frame_number': 1069}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 572, 'frame_number': 1073}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 576, 'frame_number': 1077}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 580, 'frame_number': 1081}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 584, 'frame_number': 1085}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 588, 'frame_number': 1089}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 592, 'frame_number': 1093}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 596, 'frame_number': 1097}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 2, 'episode_frame_number': 600, 'frame_number': 1101}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 604, 'frame_number': 1105}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 608, 'frame_number': 1109}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 612, 'frame_number': 1113}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 616, 'frame_number': 1117}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 620, 'frame_number': 1121}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 624, 'frame_number': 1125}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 628, 'frame_number': 1129}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 632, 'frame_number': 1133}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 636, 'frame_number': 1137}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 640, 'frame_number': 1141}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 644, 'frame_number': 1145}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 648, 'frame_number': 1149}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 652, 'frame_number': 1153}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 656, 'frame_number': 1157}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 660, 'frame_number': 1161}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 664, 'frame_number': 1165}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 668, 'frame_number': 1169}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 672, 'frame_number': 1173}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 676, 'frame_number': 1177}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 680, 'frame_number': 1181}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 684, 'frame_number': 1185}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 688, 'frame_number': 1189}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 692, 'frame_number': 1193}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 696, 'frame_number': 1197}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 700, 'frame_number': 1201}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 704, 'frame_number': 1205}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 708, 'frame_number': 1209}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 712, 'frame_number': 1213}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 716, 'frame_number': 1217}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 720, 'frame_number': 1221}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 724, 'frame_number': 1225}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 728, 'frame_number': 1229}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 1, 'episode_frame_number': 732, 'frame_number': 1233}\n",
      "Reward: 0.0, Done: False, Info:{'lives': 0, 'episode_frame_number': 733, 'frame_number': 1234}\n",
      "Reward: 0.0, Done: True, Info:{'lives': 0, 'episode_frame_number': 733, 'frame_number': 1234}\n"
     ]
    }
   ],
   "source": [
    "for _ in range(200):\n",
    "    # display the current state\n",
    "#     env.render()  # display the current state\n",
    "    \n",
    "    # get the random action \n",
    "    random_action = env.action_space.sample()\n",
    "    \n",
    "    # perform the action in current state of the environment.\n",
    "    # it turns 4 types of values as below\n",
    "    observation, reward, done, info = env.step(random_action)\n",
    "    print(f'Reward: {reward}, Done: {done}, Info:{info}')\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "    time.sleep(0.1) # slow down the game a bit\n",
    "\n",
    "# close the environment at the end of the loop\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-amount",
   "metadata": {},
   "source": [
    "If we would now again render the environment, we continue at the same stage we left - thus to start again we need to call the **reset** function.\n",
    "The reset function returns the initial state of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "manual-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-approval",
   "metadata": {},
   "source": [
    "Now we can again take a look at the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac099754",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    \n",
    "    random_action = env.action_space.sample()  # get the random action\n",
    "    observation, reward, done, info = env.step(random_action) # perform the action the current state of the environment\n",
    "    print(f\"Reward: {reward}, Done: {done}, Info: {info}\")\n",
    "    if done:  # with the done variable we can leave the loop if gym notifies us that the game is over\n",
    "        break\n",
    "    time.sleep(0.01)  # slow down the game a bit\n",
    "env.close()  # dont forget to close the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-carnival",
   "metadata": {},
   "source": [
    "As you might have noticed, there are always two versions of an environment:\n",
    "\n",
    "1. RAM Version\n",
    "2. Normal Version / Image based version\n",
    "\n",
    "Those version differ in the observation which gym returns to you. <br />\n",
    "The Ram Version only returns some properties (like the coordinates of the ball), while the normal version returns images (i.e exact the image that render() shows us).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba693251",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name_ram = 'Breakout-ram-v0' # use the RAM version\n",
    "env_ram = gym.make(env_name_ram)# create the RAM version of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87e3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_ram.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acknowledged-accordance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_ram.reset().shape # you can use the reset function to inspect the initial state of your environment.\n",
    "                      # There are only 128 values instead of the whole image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1955f292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape  # Our original environment returns an image as observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-classification",
   "metadata": {},
   "source": [
    "The next notebooks shows an application, where we can directly use the values the RAM version returns to us to create our first little agent that plays a game for us.\n",
    "\n",
    "Feel free to change the environments in this chapter and try all the available games.\n",
    "What highscores are you able to achieve?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
