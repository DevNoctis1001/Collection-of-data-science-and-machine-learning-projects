{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Flower Predictions Project\n",
    "\n",
    "This project is trying to create a Machine Learning Model which can accept features of a flower and can predict the species that flower belonged to.\n",
    "\n",
    "+ [Data](#data)\n",
    "+ [Data Processing](#dataprocessing)\n",
    "    + [Split Features and Labels](#split)\n",
    "    + [Categorical Encoding](#catencoding)\n",
    "+ [Train Test Split](#traintestsplit)\n",
    "+ [Scaling](#scaling)\n",
    "+ [Model Building](#modelbuilding)\n",
    "+ [Model Training](#modeltraining)\n",
    "+ [Model Evaluation](#modelevaluation)\n",
    "    + [Model History Metrics](#modelhistory)\n",
    "    + [Model Evaluate on Test Data](#modelevaluation)\n",
    " -----------\n",
    "+ [Preparing Model for Deployment](#prepdep)\n",
    "    + [Deployment Prep - Scale the full features dataset](#prepdepscaled)\n",
    "    + [Deployment Prep - Model Building](#prepdepmodelbuilding)\n",
    "    + [Deployment Prep - Model Training](#prepdepmodeltraining)\n",
    "    + [Deployment Prep - Save Model and Scaler](#prepdepsavemodel)\n",
    "+ [Predicting a Single New Flower](#prepdepsavemodel)\n",
    "+ [Prediction Function](#predfunc)\n",
    "----------\n",
    "+ [CODE FOR DEPLOYMENT](#codefordep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=data>Data</a>\n",
    "\n",
    "For this example we use the very common data set: [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is about flowers. \n",
    "\n",
    "From Wikipedia:\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the Gasp√© Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".[3]\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal_length</th>\n",
       "      <td>150.0</td>\n",
       "      <td>5.843333</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.80</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal_width</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_length</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.35</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal_width</th>\n",
       "      <td>150.0</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean       std  min  25%   50%  75%  max\n",
       "sepal_length  150.0  5.843333  0.828066  4.3  5.1  5.80  6.4  7.9\n",
       "sepal_width   150.0  3.057333  0.435866  2.0  2.8  3.00  3.3  4.4\n",
       "petal_length  150.0  3.758000  1.765298  1.0  1.6  4.35  5.1  6.9\n",
       "petal_width   150.0  1.199333  0.762238  0.1  0.3  1.30  1.8  2.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=dataprocessing>Data Processing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=split>Split Features and Labels</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species', axis=1)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a name=catencoding>Categorical Encoding</a>\n",
    "+ As our label has 3 different values and the problem we are trying to solve is multi categorical problem. So we need to encode those values first.\n",
    "\n",
    "### There are multiple ways to do one-hot-encoding\n",
    "+ https://stackoverflow.com/questions/47573293/unable-to-transform-string-column-to-categorical-matrix-using-keras-and-sklearn\n",
    "+ https://stackoverflow.com/questions/35107559/one-hot-encoding-of-string-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is now one-hot-encoded\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=traintestsplit>Train Test Split</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=scaling>Scaling</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <a name=modelbuilding>Model Building</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=4, activation='relu', input_shape=[4,]))\n",
    "\n",
    "model.add(Dense(units=3, activation='softmax')) # multi classification for 3 classes\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=modeltraining>Model Training</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=10,\n",
    "                                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 3s 603ms/step - loss: 1.0779 - accuracy: 0.3046 - val_loss: 1.0913 - val_accuracy: 0.2667\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0656 - accuracy: 0.3390 - val_loss: 1.0905 - val_accuracy: 0.2667\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0615 - accuracy: 0.3452 - val_loss: 1.0897 - val_accuracy: 0.2667\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0585 - accuracy: 0.3546 - val_loss: 1.0887 - val_accuracy: 0.2667\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0537 - accuracy: 0.3546 - val_loss: 1.0879 - val_accuracy: 0.2667\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0457 - accuracy: 0.3796 - val_loss: 1.0872 - val_accuracy: 0.2667\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0538 - accuracy: 0.3400 - val_loss: 1.0865 - val_accuracy: 0.2667\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0549 - accuracy: 0.3390 - val_loss: 1.0856 - val_accuracy: 0.2667\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0528 - accuracy: 0.3358 - val_loss: 1.0845 - val_accuracy: 0.2667\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0395 - accuracy: 0.3567 - val_loss: 1.0835 - val_accuracy: 0.2667\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0471 - accuracy: 0.3410 - val_loss: 1.0824 - val_accuracy: 0.2667\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0527 - accuracy: 0.3265 - val_loss: 1.0813 - val_accuracy: 0.2667\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0354 - accuracy: 0.3462 - val_loss: 1.0803 - val_accuracy: 0.2667\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0278 - accuracy: 0.3629 - val_loss: 1.0793 - val_accuracy: 0.2667\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0282 - accuracy: 0.3650 - val_loss: 1.0782 - val_accuracy: 0.2667\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0388 - accuracy: 0.3254 - val_loss: 1.0770 - val_accuracy: 0.2667\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0276 - accuracy: 0.3527 - val_loss: 1.0759 - val_accuracy: 0.2667\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0128 - accuracy: 0.4008 - val_loss: 1.0749 - val_accuracy: 0.2667\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0244 - accuracy: 0.3656 - val_loss: 1.0737 - val_accuracy: 0.2667\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0221 - accuracy: 0.3688 - val_loss: 1.0726 - val_accuracy: 0.3000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0197 - accuracy: 0.3971 - val_loss: 1.0714 - val_accuracy: 0.3000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0337 - accuracy: 0.3735 - val_loss: 1.0701 - val_accuracy: 0.3333\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0122 - accuracy: 0.4463 - val_loss: 1.0689 - val_accuracy: 0.3667\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9988 - accuracy: 0.4592 - val_loss: 1.0678 - val_accuracy: 0.3667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0300 - accuracy: 0.3992 - val_loss: 1.0665 - val_accuracy: 0.3667\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0072 - accuracy: 0.4863 - val_loss: 1.0654 - val_accuracy: 0.3667\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0238 - accuracy: 0.5135 - val_loss: 1.0641 - val_accuracy: 0.3667\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9943 - accuracy: 0.5954 - val_loss: 1.0630 - val_accuracy: 0.3667\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0015 - accuracy: 0.5844 - val_loss: 1.0617 - val_accuracy: 0.4000\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0027 - accuracy: 0.5894 - val_loss: 1.0604 - val_accuracy: 0.4000\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0044 - accuracy: 0.5967 - val_loss: 1.0590 - val_accuracy: 0.4000\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9872 - accuracy: 0.6240 - val_loss: 1.0576 - val_accuracy: 0.4333\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9851 - accuracy: 0.6521 - val_loss: 1.0561 - val_accuracy: 0.4667\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9772 - accuracy: 0.6492 - val_loss: 1.0546 - val_accuracy: 0.4667\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9978 - accuracy: 0.6238 - val_loss: 1.0528 - val_accuracy: 0.4667\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9882 - accuracy: 0.6625 - val_loss: 1.0511 - val_accuracy: 0.4667\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9851 - accuracy: 0.6679 - val_loss: 1.0493 - val_accuracy: 0.4667\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9886 - accuracy: 0.6950 - val_loss: 1.0475 - val_accuracy: 0.4667\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9976 - accuracy: 0.6356 - val_loss: 1.0457 - val_accuracy: 0.4667\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9864 - accuracy: 0.6617 - val_loss: 1.0440 - val_accuracy: 0.4667\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9853 - accuracy: 0.6721 - val_loss: 1.0423 - val_accuracy: 0.4667\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9731 - accuracy: 0.6825 - val_loss: 1.0405 - val_accuracy: 0.5000\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9608 - accuracy: 0.6867 - val_loss: 1.0388 - val_accuracy: 0.5000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9593 - accuracy: 0.7002 - val_loss: 1.0372 - val_accuracy: 0.5000\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9488 - accuracy: 0.7127 - val_loss: 1.0356 - val_accuracy: 0.5000\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9664 - accuracy: 0.6763 - val_loss: 1.0336 - val_accuracy: 0.5000\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9515 - accuracy: 0.7044 - val_loss: 1.0317 - val_accuracy: 0.5000\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9658 - accuracy: 0.7023 - val_loss: 1.0296 - val_accuracy: 0.5000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9756 - accuracy: 0.6523 - val_loss: 1.0275 - val_accuracy: 0.5000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9663 - accuracy: 0.6513 - val_loss: 1.0254 - val_accuracy: 0.5000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9488 - accuracy: 0.6867 - val_loss: 1.0235 - val_accuracy: 0.5000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9678 - accuracy: 0.6367 - val_loss: 1.0215 - val_accuracy: 0.5000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9554 - accuracy: 0.6744 - val_loss: 1.0195 - val_accuracy: 0.5333\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9414 - accuracy: 0.6681 - val_loss: 1.0176 - val_accuracy: 0.5333\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9467 - accuracy: 0.6733 - val_loss: 1.0157 - val_accuracy: 0.5333\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9528 - accuracy: 0.6723 - val_loss: 1.0137 - val_accuracy: 0.5667\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9681 - accuracy: 0.6473 - val_loss: 1.0115 - val_accuracy: 0.5667\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9470 - accuracy: 0.6608 - val_loss: 1.0096 - val_accuracy: 0.5667\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9325 - accuracy: 0.6827 - val_loss: 1.0077 - val_accuracy: 0.5667\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9517 - accuracy: 0.6598 - val_loss: 1.0055 - val_accuracy: 0.5667\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9118 - accuracy: 0.7181 - val_loss: 1.0037 - val_accuracy: 0.5667\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9342 - accuracy: 0.6775 - val_loss: 1.0017 - val_accuracy: 0.5667\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9245 - accuracy: 0.6806 - val_loss: 0.9996 - val_accuracy: 0.5667\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9356 - accuracy: 0.6462 - val_loss: 0.9974 - val_accuracy: 0.5667\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9524 - accuracy: 0.6317 - val_loss: 0.9951 - val_accuracy: 0.5667\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9167 - accuracy: 0.6806 - val_loss: 0.9931 - val_accuracy: 0.5667\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9158 - accuracy: 0.6817 - val_loss: 0.9911 - val_accuracy: 0.5667\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9081 - accuracy: 0.6942 - val_loss: 0.9890 - val_accuracy: 0.5667\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9204 - accuracy: 0.6660 - val_loss: 0.9868 - val_accuracy: 0.5667\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9111 - accuracy: 0.7067 - val_loss: 0.9847 - val_accuracy: 0.5667\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9180 - accuracy: 0.6681 - val_loss: 0.9825 - val_accuracy: 0.5667\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8924 - accuracy: 0.7244 - val_loss: 0.9804 - val_accuracy: 0.5667\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9274 - accuracy: 0.6869 - val_loss: 0.9780 - val_accuracy: 0.5667\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9124 - accuracy: 0.6692 - val_loss: 0.9758 - val_accuracy: 0.5667\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9211 - accuracy: 0.6671 - val_loss: 0.9735 - val_accuracy: 0.5667\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8912 - accuracy: 0.7025 - val_loss: 0.9714 - val_accuracy: 0.5667\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8929 - accuracy: 0.6837 - val_loss: 0.9691 - val_accuracy: 0.5667\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9066 - accuracy: 0.6546 - val_loss: 0.9667 - val_accuracy: 0.5667\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8773 - accuracy: 0.6879 - val_loss: 0.9644 - val_accuracy: 0.5667\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8846 - accuracy: 0.6890 - val_loss: 0.9619 - val_accuracy: 0.5667\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9039 - accuracy: 0.6650 - val_loss: 0.9594 - val_accuracy: 0.5667\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8785 - accuracy: 0.7015 - val_loss: 0.9571 - val_accuracy: 0.5667\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8909 - accuracy: 0.6567 - val_loss: 0.9546 - val_accuracy: 0.5667\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8642 - accuracy: 0.7035 - val_loss: 0.9521 - val_accuracy: 0.5667\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8765 - accuracy: 0.6890 - val_loss: 0.9495 - val_accuracy: 0.5667\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8855 - accuracy: 0.6827 - val_loss: 0.9468 - val_accuracy: 0.5667\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8769 - accuracy: 0.6765 - val_loss: 0.9442 - val_accuracy: 0.5667\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8900 - accuracy: 0.6712 - val_loss: 0.9416 - val_accuracy: 0.5667\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8674 - accuracy: 0.6754 - val_loss: 0.9391 - val_accuracy: 0.5667\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8434 - accuracy: 0.7192 - val_loss: 0.9366 - val_accuracy: 0.5667\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8614 - accuracy: 0.6879 - val_loss: 0.9339 - val_accuracy: 0.5667\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8583 - accuracy: 0.6910 - val_loss: 0.9312 - val_accuracy: 0.5667\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8442 - accuracy: 0.6921 - val_loss: 0.9284 - val_accuracy: 0.5667\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8578 - accuracy: 0.6723 - val_loss: 0.9256 - val_accuracy: 0.5667\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8568 - accuracy: 0.6858 - val_loss: 0.9227 - val_accuracy: 0.5667\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8465 - accuracy: 0.6931 - val_loss: 0.9198 - val_accuracy: 0.5667\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8361 - accuracy: 0.6910 - val_loss: 0.9171 - val_accuracy: 0.5667\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8533 - accuracy: 0.6744 - val_loss: 0.9142 - val_accuracy: 0.5667\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8430 - accuracy: 0.68 - 0s 19ms/step - loss: 0.8386 - accuracy: 0.6900 - val_loss: 0.9115 - val_accuracy: 0.5667\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8307 - accuracy: 0.6837 - val_loss: 0.9088 - val_accuracy: 0.5667\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8531 - accuracy: 0.6483 - val_loss: 0.9058 - val_accuracy: 0.5667\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8143 - accuracy: 0.7067 - val_loss: 0.9032 - val_accuracy: 0.5667\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8061 - accuracy: 0.7265 - val_loss: 0.9003 - val_accuracy: 0.5667\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7933 - accuracy: 0.7244 - val_loss: 0.8974 - val_accuracy: 0.5667\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8264 - accuracy: 0.6785 - val_loss: 0.8943 - val_accuracy: 0.5667\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8157 - accuracy: 0.6890 - val_loss: 0.8913 - val_accuracy: 0.5667\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8316 - accuracy: 0.6400 - val_loss: 0.8881 - val_accuracy: 0.5667\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8034 - accuracy: 0.6837 - val_loss: 0.8851 - val_accuracy: 0.5667\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8216 - accuracy: 0.6733 - val_loss: 0.8818 - val_accuracy: 0.5667\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8007 - accuracy: 0.6848 - val_loss: 0.8787 - val_accuracy: 0.5667\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7900 - accuracy: 0.7067 - val_loss: 0.8755 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8031 - accuracy: 0.6806 - val_loss: 0.8722 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8130 - accuracy: 0.6671 - val_loss: 0.8688 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8041 - accuracy: 0.6712 - val_loss: 0.8655 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7833 - accuracy: 0.7077 - val_loss: 0.8623 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8032 - accuracy: 0.6515 - val_loss: 0.8590 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.7745 - accuracy: 0.6879 - val_loss: 0.8558 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7927 - accuracy: 0.6660 - val_loss: 0.8525 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7633 - accuracy: 0.6837 - val_loss: 0.8494 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.7562 - accuracy: 0.7265 - val_loss: 0.8460 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7677 - accuracy: 0.7056 - val_loss: 0.8425 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7891 - accuracy: 0.6598 - val_loss: 0.8388 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7467 - accuracy: 0.7056 - val_loss: 0.8357 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7495 - accuracy: 0.6858 - val_loss: 0.8323 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7531 - accuracy: 0.6775 - val_loss: 0.8289 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7612 - accuracy: 0.6702 - val_loss: 0.8254 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7620 - accuracy: 0.6587 - val_loss: 0.8221 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7395 - accuracy: 0.7004 - val_loss: 0.8188 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7339 - accuracy: 0.6962 - val_loss: 0.8155 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7234 - accuracy: 0.7077 - val_loss: 0.8122 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7315 - accuracy: 0.6942 - val_loss: 0.8087 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7227 - accuracy: 0.6983 - val_loss: 0.8052 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7458 - accuracy: 0.6556 - val_loss: 0.8017 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7168 - accuracy: 0.6910 - val_loss: 0.7983 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7108 - accuracy: 0.7015 - val_loss: 0.7948 - val_accuracy: 0.6000\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7011 - accuracy: 0.7129 - val_loss: 0.7915 - val_accuracy: 0.6000\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7286 - accuracy: 0.6569 - val_loss: 0.7880 - val_accuracy: 0.6000\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7086 - accuracy: 0.6829 - val_loss: 0.7847 - val_accuracy: 0.6000\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7209 - accuracy: 0.6715 - val_loss: 0.7811 - val_accuracy: 0.6000\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6947 - accuracy: 0.7100 - val_loss: 0.7778 - val_accuracy: 0.6000\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7050 - accuracy: 0.6975 - val_loss: 0.7744 - val_accuracy: 0.6000\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6792 - accuracy: 0.7204 - val_loss: 0.7710 - val_accuracy: 0.6000\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6775 - accuracy: 0.7194 - val_loss: 0.7676 - val_accuracy: 0.6000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6790 - accuracy: 0.7204 - val_loss: 0.7642 - val_accuracy: 0.6000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6914 - accuracy: 0.6933 - val_loss: 0.7607 - val_accuracy: 0.6000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6806 - accuracy: 0.6892 - val_loss: 0.7573 - val_accuracy: 0.6000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6591 - accuracy: 0.7142 - val_loss: 0.7541 - val_accuracy: 0.6000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6729 - accuracy: 0.6850 - val_loss: 0.7507 - val_accuracy: 0.6000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6992 - accuracy: 0.65 - 0s 18ms/step - loss: 0.6717 - accuracy: 0.6902 - val_loss: 0.7474 - val_accuracy: 0.6000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6765 - accuracy: 0.6902 - val_loss: 0.7439 - val_accuracy: 0.6000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6488 - accuracy: 0.7235 - val_loss: 0.7406 - val_accuracy: 0.6000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6711 - accuracy: 0.6975 - val_loss: 0.7373 - val_accuracy: 0.6333\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6629 - accuracy: 0.6767 - val_loss: 0.7340 - val_accuracy: 0.6333\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6360 - accuracy: 0.7204 - val_loss: 0.7308 - val_accuracy: 0.6333\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6624 - accuracy: 0.6767 - val_loss: 0.7276 - val_accuracy: 0.6333\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6530 - accuracy: 0.6860 - val_loss: 0.7244 - val_accuracy: 0.6333\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6301 - accuracy: 0.7319 - val_loss: 0.7213 - val_accuracy: 0.6333\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6512 - accuracy: 0.6860 - val_loss: 0.7181 - val_accuracy: 0.6333\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6386 - accuracy: 0.6913 - val_loss: 0.7151 - val_accuracy: 0.6333\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6282 - accuracy: 0.7027 - val_loss: 0.7120 - val_accuracy: 0.6333\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6752 - accuracy: 0.6329 - val_loss: 0.7087 - val_accuracy: 0.6333\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6347 - accuracy: 0.6871 - val_loss: 0.7056 - val_accuracy: 0.6333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6552 - accuracy: 0.6496 - val_loss: 0.7026 - val_accuracy: 0.6333\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5958 - accuracy: 0.7340 - val_loss: 0.6998 - val_accuracy: 0.6333\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6118 - accuracy: 0.7058 - val_loss: 0.6968 - val_accuracy: 0.6333\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6127 - accuracy: 0.7100 - val_loss: 0.6938 - val_accuracy: 0.6333\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6341 - accuracy: 0.6694 - val_loss: 0.6908 - val_accuracy: 0.6333\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6010 - accuracy: 0.7142 - val_loss: 0.6879 - val_accuracy: 0.6333\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6008 - accuracy: 0.7027 - val_loss: 0.6850 - val_accuracy: 0.6333\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6138 - accuracy: 0.6777 - val_loss: 0.6821 - val_accuracy: 0.6333\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5875 - accuracy: 0.7194 - val_loss: 0.6793 - val_accuracy: 0.6333\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5975 - accuracy: 0.7100 - val_loss: 0.6764 - val_accuracy: 0.6333\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6235 - accuracy: 0.6612 - val_loss: 0.6734 - val_accuracy: 0.6333\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5993 - accuracy: 0.6925 - val_loss: 0.6706 - val_accuracy: 0.6333\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5777 - accuracy: 0.7206 - val_loss: 0.6679 - val_accuracy: 0.6333\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5846 - accuracy: 0.7198 - val_loss: 0.6653 - val_accuracy: 0.6333\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6307 - accuracy: 0.6448 - val_loss: 0.6625 - val_accuracy: 0.6333\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5769 - accuracy: 0.7146 - val_loss: 0.6599 - val_accuracy: 0.6333\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6085 - accuracy: 0.6917 - val_loss: 0.6572 - val_accuracy: 0.6333\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5958 - accuracy: 0.6844 - val_loss: 0.6547 - val_accuracy: 0.6333\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5793 - accuracy: 0.6917 - val_loss: 0.6521 - val_accuracy: 0.6333\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5937 - accuracy: 0.6844 - val_loss: 0.6494 - val_accuracy: 0.6333\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5662 - accuracy: 0.7271 - val_loss: 0.6469 - val_accuracy: 0.6333\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5811 - accuracy: 0.6885 - val_loss: 0.6442 - val_accuracy: 0.6333\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5819 - accuracy: 0.6856 - val_loss: 0.6416 - val_accuracy: 0.6333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5585 - accuracy: 0.7335 - val_loss: 0.6393 - val_accuracy: 0.6333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5559 - accuracy: 0.7190 - val_loss: 0.6369 - val_accuracy: 0.6333\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5899 - accuracy: 0.6783 - val_loss: 0.6343 - val_accuracy: 0.6333\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5734 - accuracy: 0.7044 - val_loss: 0.6318 - val_accuracy: 0.6333\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5564 - accuracy: 0.7179 - val_loss: 0.6293 - val_accuracy: 0.6333\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5676 - accuracy: 0.7117 - val_loss: 0.6269 - val_accuracy: 0.6333\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5482 - accuracy: 0.7262 - val_loss: 0.6246 - val_accuracy: 0.6333\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5309 - accuracy: 0.7471 - val_loss: 0.6223 - val_accuracy: 0.6333\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5501 - accuracy: 0.7075 - val_loss: 0.6200 - val_accuracy: 0.6333\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5415 - accuracy: 0.7408 - val_loss: 0.6177 - val_accuracy: 0.6333\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5328 - accuracy: 0.7548 - val_loss: 0.6154 - val_accuracy: 0.6333\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5569 - accuracy: 0.7319 - val_loss: 0.6133 - val_accuracy: 0.6333\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5370 - accuracy: 0.7392 - val_loss: 0.6110 - val_accuracy: 0.6333\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5193 - accuracy: 0.7475 - val_loss: 0.6088 - val_accuracy: 0.6333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5541 - accuracy: 0.7058 - val_loss: 0.6065 - val_accuracy: 0.6333\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5430 - accuracy: 0.7163 - val_loss: 0.6044 - val_accuracy: 0.6333\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5097 - accuracy: 0.7704 - val_loss: 0.6024 - val_accuracy: 0.6333\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5487 - accuracy: 0.7058 - val_loss: 0.6001 - val_accuracy: 0.6333\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5180 - accuracy: 0.7631 - val_loss: 0.5979 - val_accuracy: 0.6333\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5164 - accuracy: 0.7517 - val_loss: 0.5957 - val_accuracy: 0.6333\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5453 - accuracy: 0.7038 - val_loss: 0.5934 - val_accuracy: 0.6333\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5180 - accuracy: 0.7288 - val_loss: 0.5914 - val_accuracy: 0.6667\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5071 - accuracy: 0.7621 - val_loss: 0.5895 - val_accuracy: 0.6667\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5075 - accuracy: 0.7558 - val_loss: 0.5875 - val_accuracy: 0.6667\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5222 - accuracy: 0.7165 - val_loss: 0.5854 - val_accuracy: 0.6667\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5367 - accuracy: 0.7071 - val_loss: 0.5834 - val_accuracy: 0.6667\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5154 - accuracy: 0.7425 - val_loss: 0.5815 - val_accuracy: 0.6667\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5167 - accuracy: 0.7394 - val_loss: 0.5797 - val_accuracy: 0.6667\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5130 - accuracy: 0.7312 - val_loss: 0.5779 - val_accuracy: 0.6667\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4931 - accuracy: 0.7542 - val_loss: 0.5763 - val_accuracy: 0.6667\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5019 - accuracy: 0.7635 - val_loss: 0.5746 - val_accuracy: 0.6667\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4933 - accuracy: 0.7875 - val_loss: 0.5729 - val_accuracy: 0.6667\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4959 - accuracy: 0.7750 - val_loss: 0.5713 - val_accuracy: 0.6667\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5251 - accuracy: 0.7010 - val_loss: 0.5692 - val_accuracy: 0.7000\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4699 - accuracy: 0.8052 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4972 - accuracy: 0.7656 - val_loss: 0.5657 - val_accuracy: 0.7000\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5149 - accuracy: 0.7125 - val_loss: 0.5638 - val_accuracy: 0.7000\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4874 - accuracy: 0.7677 - val_loss: 0.5621 - val_accuracy: 0.7000\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4754 - accuracy: 0.7823 - val_loss: 0.5604 - val_accuracy: 0.7000\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4992 - accuracy: 0.7417 - val_loss: 0.5586 - val_accuracy: 0.7000\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4927 - accuracy: 0.7573 - val_loss: 0.5570 - val_accuracy: 0.7000\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5000 - accuracy: 0.7417 - val_loss: 0.5553 - val_accuracy: 0.7000\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5014 - accuracy: 0.7271 - val_loss: 0.5534 - val_accuracy: 0.7333\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4884 - accuracy: 0.7281 - val_loss: 0.5517 - val_accuracy: 0.7333\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4807 - accuracy: 0.7615 - val_loss: 0.5503 - val_accuracy: 0.7333\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4706 - accuracy: 0.7646 - val_loss: 0.5487 - val_accuracy: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4799 - accuracy: 0.7606 - val_loss: 0.5472 - val_accuracy: 0.7333\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4884 - accuracy: 0.7304 - val_loss: 0.5456 - val_accuracy: 0.7333\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4690 - accuracy: 0.7669 - val_loss: 0.5443 - val_accuracy: 0.7333\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4870 - accuracy: 0.7460 - val_loss: 0.5427 - val_accuracy: 0.7333\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4827 - accuracy: 0.7471 - val_loss: 0.5411 - val_accuracy: 0.7667\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4776 - accuracy: 0.7648 - val_loss: 0.5398 - val_accuracy: 0.7667\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5020 - accuracy: 0.7148 - val_loss: 0.5383 - val_accuracy: 0.7667\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4693 - accuracy: 0.7585 - val_loss: 0.5369 - val_accuracy: 0.7667\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4791 - accuracy: 0.7429 - val_loss: 0.5356 - val_accuracy: 0.7667\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4762 - accuracy: 0.7471 - val_loss: 0.5343 - val_accuracy: 0.7667\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4695 - accuracy: 0.7617 - val_loss: 0.5331 - val_accuracy: 0.7667\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4753 - accuracy: 0.7304 - val_loss: 0.5318 - val_accuracy: 0.7667\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4570 - accuracy: 0.7648 - val_loss: 0.5305 - val_accuracy: 0.7667\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4794 - accuracy: 0.7335 - val_loss: 0.5291 - val_accuracy: 0.7667\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4428 - accuracy: 0.7815 - val_loss: 0.5280 - val_accuracy: 0.7667\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4765 - accuracy: 0.7408 - val_loss: 0.5265 - val_accuracy: 0.7667\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4647 - accuracy: 0.7660 - val_loss: 0.5251 - val_accuracy: 0.7667\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4668 - accuracy: 0.7692 - val_loss: 0.5238 - val_accuracy: 0.7667\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4828 - accuracy: 0.7410 - val_loss: 0.5223 - val_accuracy: 0.8000\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4853 - accuracy: 0.7500 - val_loss: 0.5210 - val_accuracy: 0.8000\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4721 - accuracy: 0.7781 - val_loss: 0.5197 - val_accuracy: 0.8000\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4738 - accuracy: 0.7771 - val_loss: 0.5184 - val_accuracy: 0.8000\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.5174 - val_accuracy: 0.8000\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5164 - val_accuracy: 0.8000\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4326 - accuracy: 0.8302 - val_loss: 0.5154 - val_accuracy: 0.8000\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4430 - accuracy: 0.7792 - val_loss: 0.5140 - val_accuracy: 0.8000\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4427 - accuracy: 0.7958 - val_loss: 0.5128 - val_accuracy: 0.8000\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4662 - accuracy: 0.7877 - val_loss: 0.5115 - val_accuracy: 0.8000\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4569 - accuracy: 0.7806 - val_loss: 0.5102 - val_accuracy: 0.8000\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4636 - accuracy: 0.8110 - val_loss: 0.5091 - val_accuracy: 0.8000\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4474 - accuracy: 0.8173 - val_loss: 0.5079 - val_accuracy: 0.8000\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.4501 - accuracy: 0.8340 - val_loss: 0.5068 - val_accuracy: 0.8000\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4494 - accuracy: 0.7777 - val_loss: 0.5055 - val_accuracy: 0.8000\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4455 - accuracy: 0.8163 - val_loss: 0.5042 - val_accuracy: 0.8000\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4446 - accuracy: 0.8183 - val_loss: 0.5030 - val_accuracy: 0.8000\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4557 - accuracy: 0.8008 - val_loss: 0.5019 - val_accuracy: 0.8000\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4421 - accuracy: 0.8342 - val_loss: 0.5009 - val_accuracy: 0.8000\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4435 - accuracy: 0.8352 - val_loss: 0.4998 - val_accuracy: 0.8000\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4356 - accuracy: 0.8477 - val_loss: 0.4988 - val_accuracy: 0.8000\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4506 - accuracy: 0.8175 - val_loss: 0.4976 - val_accuracy: 0.8000\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4307 - accuracy: 0.8456 - val_loss: 0.4965 - val_accuracy: 0.8000\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4417 - accuracy: 0.8321 - val_loss: 0.4954 - val_accuracy: 0.8000\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4433 - accuracy: 0.8071 - val_loss: 0.4943 - val_accuracy: 0.8000\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4569 - accuracy: 0.8040 - val_loss: 0.4932 - val_accuracy: 0.8000\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4307 - accuracy: 0.8279 - val_loss: 0.4921 - val_accuracy: 0.8000\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4588 - accuracy: 0.8208 - val_loss: 0.4910 - val_accuracy: 0.8000\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4555 - accuracy: 0.8198 - val_loss: 0.4900 - val_accuracy: 0.8000\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4319 - accuracy: 0.8406 - val_loss: 0.4892 - val_accuracy: 0.8000\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4149 - accuracy: 0.8635 - val_loss: 0.4883 - val_accuracy: 0.8000\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4414 - accuracy: 0.8146 - val_loss: 0.4872 - val_accuracy: 0.8333\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4142 - accuracy: 0.8437 - val_loss: 0.4862 - val_accuracy: 0.8333\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4346 - accuracy: 0.8177 - val_loss: 0.4852 - val_accuracy: 0.8333\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4202 - accuracy: 0.8375 - val_loss: 0.4843 - val_accuracy: 0.8333\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3967 - accuracy: 0.8427 - val_loss: 0.4834 - val_accuracy: 0.8333\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4471 - accuracy: 0.8198 - val_loss: 0.4823 - val_accuracy: 0.8333\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4261 - accuracy: 0.8271 - val_loss: 0.4814 - val_accuracy: 0.8333\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4255 - accuracy: 0.8427 - val_loss: 0.4805 - val_accuracy: 0.8333\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4353 - accuracy: 0.8406 - val_loss: 0.4796 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4299 - accuracy: 0.8469 - val_loss: 0.4787 - val_accuracy: 0.8333\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4153 - accuracy: 0.8740 - val_loss: 0.4781 - val_accuracy: 0.8333\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3984 - accuracy: 0.8687 - val_loss: 0.4774 - val_accuracy: 0.8333\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4152 - accuracy: 0.8354 - val_loss: 0.4764 - val_accuracy: 0.8333\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3980 - accuracy: 0.8521 - val_loss: 0.4755 - val_accuracy: 0.8333\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4043 - accuracy: 0.8490 - val_loss: 0.4744 - val_accuracy: 0.8333\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4248 - accuracy: 0.8146 - val_loss: 0.4733 - val_accuracy: 0.8333\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4275 - accuracy: 0.8219 - val_loss: 0.4724 - val_accuracy: 0.8333\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4386 - accuracy: 0.8398 - val_loss: 0.4716 - val_accuracy: 0.8333\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4154 - accuracy: 0.8398 - val_loss: 0.4708 - val_accuracy: 0.8333\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4301 - accuracy: 0.8127 - val_loss: 0.4700 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc6c68cdf40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, y=y_train,\n",
    "             validation_data=(scaled_X_test, y_test),\n",
    "             epochs=300,\n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=modelevaluation>Model Evaluation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=modelhistory>Model History Metrics</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.066882</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.091250</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.064567</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.090540</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.061760</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.089653</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.059447</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.088720</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.056945</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.087869</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.066882      0.35  1.091250      0.266667\n",
       "1  1.064567      0.35  1.090540      0.266667\n",
       "2  1.061760      0.35  1.089653      0.266667\n",
       "3  1.059447      0.35  1.088720      0.266667\n",
       "4  1.056945      0.35  1.087869      0.266667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss', 'val_loss']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=modelevaluation>Model Evaluate on Test Data/a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.470024973154068, 0.8333333134651184]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test, y_test, verbose=0) # final loss , final accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "------\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=prepdep>Preparing Model for Deployment</a>\n",
    "+ Once we satsify with our model, we need to prepare model deployment for real world.\n",
    "+ In this case, we might want to the best of our model and we need to retrain our model on full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = len(metrics)\n",
    "\n",
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=prepdepscaled>Deployment Prep - Scale the full features dataset</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=prepdepmodelbuilding>Deployment Prep - Model Building</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, activation='relu', input_shape=[4,]))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=prepdepmodeltraining>Deployment Prep - Model Training</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 4ms/step - loss: 1.1752 - accuracy: 0.3574\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1419 - accuracy: 0.3677\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1605 - accuracy: 0.3251\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1518 - accuracy: 0.3190\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1431 - accuracy: 0.3550\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1315 - accuracy: 0.3659\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1343 - accuracy: 0.3533\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1423 - accuracy: 0.3077\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1332 - accuracy: 0.3429\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1290 - accuracy: 0.3468\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1293 - accuracy: 0.3155\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1364 - accuracy: 0.3355\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1277 - accuracy: 0.3121\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1276 - accuracy: 0.3464\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1346 - accuracy: 0.3151\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1274 - accuracy: 0.3372\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1242 - accuracy: 0.3359\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1272 - accuracy: 0.3038\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1225 - accuracy: 0.3273\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1193 - accuracy: 0.3459\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1288 - accuracy: 0.3094\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1226 - accuracy: 0.3285\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1203 - accuracy: 0.2981\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1215 - accuracy: 0.3089\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1150 - accuracy: 0.3232\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1201 - accuracy: 0.3023\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1150 - accuracy: 0.2970\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1157 - accuracy: 0.2974\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1123 - accuracy: 0.3077\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1151 - accuracy: 0.2583\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1139 - accuracy: 0.2573\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1153 - accuracy: 0.2320\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1151 - accuracy: 0.2110\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1106 - accuracy: 0.2340\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1110 - accuracy: 0.2096\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1149 - accuracy: 0.2051\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1106 - accuracy: 0.1951\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1117 - accuracy: 0.1955\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1107 - accuracy: 0.2055\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1096 - accuracy: 0.2046\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.1063 - accuracy: 0.21 - 0s 2ms/step - loss: 1.1088 - accuracy: 0.1858\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1089 - accuracy: 0.1376\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1085 - accuracy: 0.2040\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1066 - accuracy: 0.1767\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1064 - accuracy: 0.1924\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1095 - accuracy: 0.1689\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1075 - accuracy: 0.1889\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1081 - accuracy: 0.1616\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1054 - accuracy: 0.1893\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1038 - accuracy: 0.2123\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1044 - accuracy: 0.1732\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1060 - accuracy: 0.1507\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1008 - accuracy: 0.1745\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1012 - accuracy: 0.1945\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1036 - accuracy: 0.1902\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1038 - accuracy: 0.1763\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1014 - accuracy: 0.1929\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1031 - accuracy: 0.1655\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1031 - accuracy: 0.1790\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0998 - accuracy: 0.2203\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1021 - accuracy: 0.1973\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0992 - accuracy: 0.2282\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.2475\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1022 - accuracy: 0.2064\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0984 - accuracy: 0.2480\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0985 - accuracy: 0.2202\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0994 - accuracy: 0.2469\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0949 - accuracy: 0.2917\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0935 - accuracy: 0.3049\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0964 - accuracy: 0.2706\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0929 - accuracy: 0.3114\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0921 - accuracy: 0.3489\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0935 - accuracy: 0.2612\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0902 - accuracy: 0.3215\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0893 - accuracy: 0.3355\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0896 - accuracy: 0.3289\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0875 - accuracy: 0.3069\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0870 - accuracy: 0.3125\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0845 - accuracy: 0.3542\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0822 - accuracy: 0.3641\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0825 - accuracy: 0.3529\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0840 - accuracy: 0.3038\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0807 - accuracy: 0.3394\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0786 - accuracy: 0.3385\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0767 - accuracy: 0.3255\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0760 - accuracy: 0.3424\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0779 - accuracy: 0.3307\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0711 - accuracy: 0.3438\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0683 - accuracy: 0.3555\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0710 - accuracy: 0.3498\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0710 - accuracy: 0.3368\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0699 - accuracy: 0.3490\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0693 - accuracy: 0.3147\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0696 - accuracy: 0.3090\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0632 - accuracy: 0.3904\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0642 - accuracy: 0.4607\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0650 - accuracy: 0.4578\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0575 - accuracy: 0.5169\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0575 - accuracy: 0.5392\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0618 - accuracy: 0.5046\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0584 - accuracy: 0.5095\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0524 - accuracy: 0.5847\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0566 - accuracy: 0.5426\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0515 - accuracy: 0.6035\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0488 - accuracy: 0.6035\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0501 - accuracy: 0.5732\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0452 - accuracy: 0.5806\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0426 - accuracy: 0.6180\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0421 - accuracy: 0.6020\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0403 - accuracy: 0.6215\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0365 - accuracy: 0.6221\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0345 - accuracy: 0.6512\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0351 - accuracy: 0.6456\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0328 - accuracy: 0.6435\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0316 - accuracy: 0.6044\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0240 - accuracy: 0.6721\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0302 - accuracy: 0.6166\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0218 - accuracy: 0.6535\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.6509\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0181 - accuracy: 0.6253\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0160 - accuracy: 0.6088\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0135 - accuracy: 0.6335\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0111 - accuracy: 0.6439\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0070 - accuracy: 0.6431\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0026 - accuracy: 0.6613\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0012 - accuracy: 0.6699\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0015 - accuracy: 0.6626\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 308us/step - loss: 0.9987 - accuracy: 0.6323\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.6826\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.6375\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9872 - accuracy: 0.6513\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9866 - accuracy: 0.6109\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9816 - accuracy: 0.6322\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9807 - accuracy: 0.6365\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9762 - accuracy: 0.6013\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9742 - accuracy: 0.6004\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9696 - accuracy: 0.6276\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9674 - accuracy: 0.6194\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9648 - accuracy: 0.6005\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 823us/step - loss: 0.9624 - accuracy: 0.5631\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9607 - accuracy: 0.5837\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9558 - accuracy: 0.4880\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9510 - accuracy: 0.4940\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9495 - accuracy: 0.4947\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9473 - accuracy: 0.4716\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9430 - accuracy: 0.4750\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9393 - accuracy: 0.4527\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9356 - accuracy: 0.4568\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9327 - accuracy: 0.3640\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9316 - accuracy: 0.4425\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9297 - accuracy: 0.3847\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9280 - accuracy: 0.4157\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.3982\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9197 - accuracy: 0.4286\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9134 - accuracy: 0.4265\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.4141\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9045 - accuracy: 0.4701\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9025 - accuracy: 0.4790\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9009 - accuracy: 0.4996\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8966 - accuracy: 0.4825\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.5783\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8887 - accuracy: 0.6672\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8905 - accuracy: 0.5922\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8917 - accuracy: 0.6222\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8864 - accuracy: 0.6314\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8826 - accuracy: 0.6419\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8747 - accuracy: 0.6463\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8714 - accuracy: 0.7092\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8670 - accuracy: 0.6866\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8682 - accuracy: 0.6480\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8629 - accuracy: 0.6437\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8607 - accuracy: 0.6832\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8609 - accuracy: 0.6563\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8564 - accuracy: 0.6758\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8518 - accuracy: 0.7005\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8458 - accuracy: 0.6918\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8501 - accuracy: 0.6641\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8415 - accuracy: 0.6589\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8437 - accuracy: 0.6602\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8399 - accuracy: 0.6398\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8391 - accuracy: 0.6502\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8351 - accuracy: 0.6558\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8341 - accuracy: 0.6649\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8203 - accuracy: 0.6793\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8276 - accuracy: 0.6549\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8202 - accuracy: 0.6645\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8162 - accuracy: 0.6832\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8184 - accuracy: 0.6437\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8095 - accuracy: 0.6636\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8095 - accuracy: 0.6727\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8038 - accuracy: 0.6701\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8098 - accuracy: 0.6454\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8027 - accuracy: 0.6541\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8001 - accuracy: 0.6584\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7918 - accuracy: 0.6797\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7891 - accuracy: 0.6979\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7923 - accuracy: 0.6697\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.6866\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7825 - accuracy: 0.6840\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.6758\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7762 - accuracy: 0.6944\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7682 - accuracy: 0.6923\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7752 - accuracy: 0.6558\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7704 - accuracy: 0.6797\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7795 - accuracy: 0.6424\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7747 - accuracy: 0.6545\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7587 - accuracy: 0.6884\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7682 - accuracy: 0.6445\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7594 - accuracy: 0.6788\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7559 - accuracy: 0.6719\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7646 - accuracy: 0.6523\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7564 - accuracy: 0.6536\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.6623\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7602 - accuracy: 0.6163\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7388 - accuracy: 0.6884\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7517 - accuracy: 0.6454\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.6237\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7316 - accuracy: 0.6914\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7379 - accuracy: 0.6589\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7328 - accuracy: 0.6693\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7320 - accuracy: 0.6645\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7368 - accuracy: 0.6424\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7358 - accuracy: 0.6497\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7345 - accuracy: 0.6367\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7191 - accuracy: 0.6879\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7152 - accuracy: 0.6827\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.7161\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.6888\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7254 - accuracy: 0.6345\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7291 - accuracy: 0.6241\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7089 - accuracy: 0.6736\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.6766\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7220 - accuracy: 0.6250\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.6658\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.6567\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6931\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.6680\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7087 - accuracy: 0.6376\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.6662\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.6632\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.6684\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.6623\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.6133\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.6905\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6855 - accuracy: 0.6632\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6662\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6813 - accuracy: 0.6788\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6814 - accuracy: 0.6654\n",
      "Epoch 249/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6719\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.7118\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.6771\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6748 - accuracy: 0.6693\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6570 - accuracy: 0.7153\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6910\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.6311\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.6810\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.6363\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.6736\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6684\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6771\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6640 - accuracy: 0.6641\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.7031\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6593\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.6558\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6731 - accuracy: 0.6107\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6793\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6684\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6979\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6484\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6671\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6484\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6997\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.7001\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6426 - accuracy: 0.6558\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6849\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6263\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6797\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6732\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6584\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6871\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6697\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6602\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6493\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6351 - accuracy: 0.6471\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6636\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6480\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6766\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6875\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6749\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6532\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6879\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.6975\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6515\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6645\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6593\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.6684\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.6194\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6710\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6801\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc6c70c2100>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X, y=y,\n",
    "             epochs=epochs,\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=prepdepsavemodel>Deployment Prep - Save Model and Scaler</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/iris_scaler.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, '../Models/iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "--------\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=prepdepsavemodel>Predicting a Single New Flower</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and scaler (just for testing purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model = load_model('../Models/final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_scaler = joblib.load('../Models/iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Test Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "    'sepal_length': 5.1,\n",
    "    'sepal_width': 3.5,\n",
    "    'petal_length': 1.4,\n",
    "    'petal_width': 0.2, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_example.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### our encoder has classes of species with related index\n",
    "+ setosa at index 0, versicolor at index 1, virginica at index 2\n",
    "+ if flower is belonged to that class, their related index value will be lighted up with 1 (one-hot-encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=predfunc>Prediction Function</a>\n",
    "\n",
    "Resource why we use axis=-1 in predict() method: https://numpy.astrotech.io/array-axis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model, scaler, sample_json):\n",
    "    \n",
    "    sepal_length = sample_json['sepal_length']\n",
    "    sepal_width = sample_json['sepal_width']\n",
    "    petal_length = sample_json['petal_length']\n",
    "    petal_width = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    class_index = np.argmax(model.predict(flower), axis=-1)[0]\n",
    "    \n",
    "    return classes[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call the function for predictions\n",
    "return_prediction(iris_model, iris_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=codefordep>CODE FOR DEPLOYMENT</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "iris_model = load_model('../Models/final_iris_model.h5')\n",
    "iris_scaler = joblib.load('../Models/iris_scaler.pkl')\n",
    "\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    \n",
    "    sepal_length = sample_json['sepal_length']\n",
    "    sepal_width = sample_json['sepal_width']\n",
    "    petal_length = sample_json['petal_length']\n",
    "    petal_width = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    class_index = np.argmax(model.predict(flower), axis=-1)[0]\n",
    "    \n",
    "    return classes[class_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-datascience",
   "language": "python",
   "name": "venv-datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
